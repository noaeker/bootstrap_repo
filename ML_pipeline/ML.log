INFO:root:Program = iqtree
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134559, 'fp_0.5': 7363, 'fn_0.5': 5698, 'tp_0.5': 23736, 'mcc_0.5': 0.7384016934382123, 'tn_0.95': 115966, 'fp_0.95': 25956, 'fn_0.95': 540, 'tp_0.95': 28894, 'mcc_0.95': 0.6458116772905071, 'AUC': 0.9679973172437328, 'brier_loss': 0.053090024612646274, 'logloss': 0.16918290392668112, 'average_precision': 0.9933204475771119, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315934, 'fp_0.5': 16526, 'fn_0.5': 12703, 'tp_0.5': 55955, 'mcc_0.5': 0.7491374355253194, 'tn_0.95': 272389, 'fp_0.95': 60071, 'fn_0.95': 480, 'tp_0.95': 68178, 'mcc_0.95': 0.6560540565636024, 'AUC': 0.9727632669769926, 'brier_loss': 0.050186186174245716, 'logloss': 0.1567342985991989, 'average_precision': 0.9945166902098895, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134559, 'fp_0.5': 7363, 'fn_0.5': 5698, 'tp_0.5': 23736, 'mcc_0.5': 0.7384016934382123, 'tn_0.95': 115966, 'fp_0.95': 25956, 'fn_0.95': 540, 'tp_0.95': 28894, 'mcc_0.95': 0.6458116772905071, 'AUC': 0.9679973172437328, 'brier_loss': 0.053090024612646274, 'logloss': 0.16918290392668112, 'average_precision': 0.9933204475771119, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315934, 'fp_0.5': 16526, 'fn_0.5': 12703, 'tp_0.5': 55955, 'mcc_0.5': 0.7491374355253194, 'tn_0.95': 272389, 'fp_0.95': 60071, 'fn_0.95': 480, 'tp_0.95': 68178, 'mcc_0.95': 0.6560540565636024, 'AUC': 0.9727632669769926, 'brier_loss': 0.050186186174245716, 'logloss': 0.1567342985991989, 'average_precision': 0.9945166902098895, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 140003, 'fp_0.5': 1919, 'fn_0.5': 16299, 'tp_0.5': 13135, 'mcc_0.5': 0.5765797833689706, 'tn_0.95': 120324, 'fp_0.95': 21598, 'fn_0.95': 3396, 'tp_0.95': 26038, 'mcc_0.95': 0.6166440934421157, 'AUC': 0.9330217849365996, 'brier_loss': 0.07580832885921708, 'logloss': 0.4079544491870929, 'average_precision': 0.9802857495185502, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 328094, 'fp_0.5': 4366, 'fn_0.5': 37486, 'tp_0.5': 31172, 'mcc_0.5': 0.5843915633389923, 'tn_0.95': 281870, 'fp_0.95': 50590, 'fn_0.95': 7891, 'tp_0.95': 60767, 'mcc_0.95': 0.6164258969810044, 'AUC': 0.9337417602238112, 'brier_loss': 0.07473375889389157, 'logloss': 0.40621606200976024, 'average_precision': 0.9804913008982211, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135675, 'fp_0.5': 6247, 'fn_0.5': 9443, 'tp_0.5': 19991, 'mcc_0.5': 0.6652868896228797, 'tn_0.95': 101191, 'fp_0.95': 40731, 'fn_0.95': 1562, 'tp_0.95': 27872, 'mcc_0.95': 0.5080223374290229, 'AUC': 0.9329541494242702, 'brier_loss': 0.06704999688107667, 'logloss': 0.22638812832531655, 'average_precision': 0.9802428621226617, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 318039, 'fp_0.5': 14421, 'fn_0.5': 21597, 'tp_0.5': 47061, 'mcc_0.5': 0.6712942091787137, 'tn_0.95': 237474, 'fp_0.95': 94986, 'fn_0.95': 3680, 'tp_0.95': 64978, 'mcc_0.95': 0.5082268097289823, 'AUC': 0.9337686153872756, 'brier_loss': 0.06609204233419816, 'logloss': 0.22399146328164196, 'average_precision': 0.980465293609326, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134473, 'fp_0.5': 7449, 'fn_0.5': 5445, 'tp_0.5': 23989, 'mcc_0.5': 0.7430847690577259, 'tn_0.95': 116943, 'fp_0.95': 24979, 'fn_0.95': 535, 'tp_0.95': 28899, 'mcc_0.95': 0.6546403839885598, 'AUC': 0.9689689075688983, 'brier_loss': 0.05240563872413522, 'logloss': 0.16668391817186928, 'average_precision': 0.9935486847901263, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315720, 'fp_0.5': 16740, 'fn_0.5': 12145, 'tp_0.5': 56513, 'mcc_0.5': 0.7533518939174298, 'tn_0.95': 274592, 'fp_0.95': 57868, 'fn_0.95': 482, 'tp_0.95': 68176, 'mcc_0.95': 0.6644628605452667, 'AUC': 0.9735755866597875, 'brier_loss': 0.049465252283107546, 'logloss': 0.15434309456738743, 'average_precision': 0.9946959080573292, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aLRT_iqtree_support
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 134747, 'fp_0.5': 7175, 'fn_0.5': 6861, 'tp_0.5': 22573, 'mcc_0.5': 0.7133451860353393, 'tn_0.95': 125852, 'fp_0.95': 16070, 'fn_0.95': 2629, 'tp_0.95': 26805, 'mcc_0.95': 0.6944350240494798, 'AUC': 0.9471022859396526, 'brier_loss': 0.06434866269182286, 'logloss': 0.4015620967262793, 'average_precision': 0.9848633151870705, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315724, 'fp_0.5': 16736, 'fn_0.5': 15775, 'tp_0.5': 52883, 'mcc_0.5': 0.7159477036505506, 'tn_0.95': 294889, 'fp_0.95': 37571, 'fn_0.95': 5799, 'tp_0.95': 62859, 'mcc_0.95': 0.6977279513086468, 'AUC': 0.9497259028345781, 'brier_loss': 0.06339707603961925, 'logloss': 0.37792485757452987, 'average_precision': 0.9859355841881249, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135026, 'fp_0.5': 6896, 'fn_0.5': 7157, 'tp_0.5': 22277, 'mcc_0.5': 0.7107636891915144, 'tn_0.95': 114277, 'fp_0.95': 27645, 'fn_0.95': 1213, 'tp_0.95': 28221, 'mcc_0.95': 0.6147469020684697, 'AUC': 0.9470403844698059, 'brier_loss': 0.060373407003225917, 'logloss': 0.201673116788213, 'average_precision': 0.9845882596477383, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316453, 'fp_0.5': 16007, 'fn_0.5': 16374, 'tp_0.5': 52284, 'mcc_0.5': 0.7148862427221206, 'tn_0.95': 267697, 'fp_0.95': 64763, 'fn_0.95': 2535, 'tp_0.95': 66123, 'mcc_0.95': 0.6171901168079329, 'AUC': 0.9498390883301526, 'brier_loss': 0.05921713145387346, 'logloss': 0.19711168043828803, 'average_precision': 0.9856998180307863, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134547, 'fp_0.5': 7375, 'fn_0.5': 5687, 'tp_0.5': 23747, 'mcc_0.5': 0.7384722221717691, 'tn_0.95': 116223, 'fp_0.95': 25699, 'fn_0.95': 556, 'tp_0.95': 28878, 'mcc_0.95': 0.6476936290209361, 'AUC': 0.968015189416056, 'brier_loss': 0.05312052271112425, 'logloss': 0.16917414166994338, 'average_precision': 0.9933336272340988, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315873, 'fp_0.5': 16587, 'fn_0.5': 12666, 'tp_0.5': 55992, 'mcc_0.5': 0.7490908936769347, 'tn_0.95': 272964, 'fp_0.95': 59496, 'fn_0.95': 481, 'tp_0.95': 68177, 'mcc_0.95': 0.6582261091216464, 'AUC': 0.9728449080810898, 'brier_loss': 0.050165606303705604, 'logloss': 0.15653234177137418, 'average_precision': 0.9945407998125757, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aBayes_iqtree_support
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 133591, 'fp_0.5': 8331, 'fn_0.5': 5937, 'tp_0.5': 23497, 'mcc_0.5': 0.7173103091682481, 'tn_0.95': 119799, 'fp_0.95': 22123, 'fn_0.95': 1632, 'tp_0.95': 27802, 'mcc_0.95': 0.6546699232601114, 'AUC': 0.9466305264696899, 'brier_loss': 0.06381099192021289, 'logloss': 0.33543675351780333, 'average_precision': 0.9842064009158841, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312941, 'fp_0.5': 19519, 'fn_0.5': 13608, 'tp_0.5': 55050, 'mcc_0.5': 0.7194539559226876, 'tn_0.95': 280673, 'fp_0.95': 51787, 'fn_0.95': 3555, 'tp_0.95': 65103, 'mcc_0.95': 0.6568503084783186, 'AUC': 0.948936982941273, 'brier_loss': 0.0629768449790336, 'logloss': 0.3166169252453231, 'average_precision': 0.9851595090273626, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135035, 'fp_0.5': 6887, 'fn_0.5': 7273, 'tp_0.5': 22161, 'mcc_0.5': 0.708080449206778, 'tn_0.95': 112768, 'fp_0.95': 29154, 'fn_0.95': 1104, 'tp_0.95': 28330, 'mcc_0.95': 0.6047882998557575, 'AUC': 0.9465212145969868, 'brier_loss': 0.060906081378940165, 'logloss': 0.20273258734358163, 'average_precision': 0.9841398744968903, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316429, 'fp_0.5': 16031, 'fn_0.5': 16506, 'tp_0.5': 52152, 'mcc_0.5': 0.713335877745869, 'tn_0.95': 264115, 'fp_0.95': 68345, 'fn_0.95': 2275, 'tp_0.95': 66383, 'mcc_0.95': 0.6071250658354199, 'AUC': 0.9491109449263405, 'brier_loss': 0.059771029326519426, 'logloss': 0.1982456989151873, 'average_precision': 0.98515268854034, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134588, 'fp_0.5': 7334, 'fn_0.5': 5704, 'tp_0.5': 23730, 'mcc_0.5': 0.7387258728742426, 'tn_0.95': 116263, 'fp_0.95': 25659, 'fn_0.95': 558, 'tp_0.95': 28876, 'mcc_0.95': 0.6479997074622573, 'AUC': 0.9679275194661873, 'brier_loss': 0.053124419657211056, 'logloss': 0.16935712116073331, 'average_precision': 0.993296130626879, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315929, 'fp_0.5': 16531, 'fn_0.5': 12758, 'tp_0.5': 55900, 'mcc_0.5': 0.7485398403428389, 'tn_0.95': 273224, 'fp_0.95': 59236, 'fn_0.95': 490, 'tp_0.95': 68168, 'mcc_0.95': 0.6591234267584959, 'AUC': 0.9727936610593706, 'brier_loss': 0.050219921668431464, 'logloss': 0.15675045823129857, 'average_precision': 0.9945333035358767, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Program = raxml
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_all_ML_boot_raxml', 'feature_mean_all_ML_boot_raxml_binary', 'feature_mean_all_ML_boot_raxml_neighbors', 'feature_mean_all_ML_boot_raxml_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 23
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 23 out of 23
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134744, 'fp_0.5': 7259, 'fn_0.5': 5571, 'tp_0.5': 23782, 'mcc_0.5': 0.7425869612721591, 'tn_0.95': 117014, 'fp_0.95': 24989, 'fn_0.95': 475, 'tp_0.95': 28878, 'mcc_0.95': 0.6556041782420439, 'AUC': 0.9694796235991486, 'brier_loss': 0.05236415665144898, 'logloss': 0.16535303554461558, 'average_precision': 0.9937603689907011, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316320, 'fp_0.5': 16397, 'fn_0.5': 12533, 'tp_0.5': 55868, 'mcc_0.5': 0.7510628681120258, 'tn_0.95': 275249, 'fp_0.95': 57468, 'fn_0.95': 500, 'tp_0.95': 67901, 'mcc_0.95': 0.6652929718889221, 'AUC': 0.9732706428709277, 'brier_loss': 0.04970529950570415, 'logloss': 0.15470794096672524, 'average_precision': 0.9946655922450813, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 23
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 23 out of 23
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134744, 'fp_0.5': 7259, 'fn_0.5': 5571, 'tp_0.5': 23782, 'mcc_0.5': 0.7425869612721591, 'tn_0.95': 117014, 'fp_0.95': 24989, 'fn_0.95': 475, 'tp_0.95': 28878, 'mcc_0.95': 0.6556041782420439, 'AUC': 0.9694796235991486, 'brier_loss': 0.05236415665144898, 'logloss': 0.16535303554461558, 'average_precision': 0.9937603689907011, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316320, 'fp_0.5': 16397, 'fn_0.5': 12533, 'tp_0.5': 55868, 'mcc_0.5': 0.7510628681120258, 'tn_0.95': 275249, 'fp_0.95': 57468, 'fn_0.95': 500, 'tp_0.95': 67901, 'mcc_0.95': 0.6652929718889221, 'AUC': 0.9732706428709277, 'brier_loss': 0.04970529950570415, 'logloss': 0.15470794096672524, 'average_precision': 0.9946655922450813, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 24 out of 24
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 136233, 'fp_0.5': 5770, 'fn_0.5': 10076, 'tp_0.5': 19277, 'mcc_0.5': 0.6570688289528165, 'tn_0.95': 96612, 'fp_0.95': 45391, 'fn_0.95': 381, 'tp_0.95': 28972, 'mcc_0.95': 0.5073343519403142, 'AUC': 0.9494182240845419, 'brier_loss': 0.06634679906160275, 'logloss': 0.2263965218592486, 'average_precision': 0.9885591489157667, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 318991, 'fp_0.5': 13726, 'fn_0.5': 23095, 'tp_0.5': 45306, 'mcc_0.5': 0.6593590459063141, 'tn_0.95': 226680, 'fp_0.95': 106037, 'fn_0.95': 858, 'tp_0.95': 67543, 'mcc_0.95': 0.5076444389002933, 'AUC': 0.9507938093647492, 'brier_loss': 0.06550648362825902, 'logloss': 0.22152280155772772, 'average_precision': 0.988979408745456, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 136233, 'fp_0.5': 5770, 'fn_0.5': 10076, 'tp_0.5': 19277, 'mcc_0.5': 0.6570688289528165, 'tn_0.95': 102534, 'fp_0.95': 39469, 'fn_0.95': 638, 'tp_0.95': 28715, 'mcc_0.95': 0.53907502649989, 'AUC': 0.9493700846422868, 'brier_loss': 0.06546485280421822, 'logloss': 0.2082439616708939, 'average_precision': 0.9884275387566983, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 318991, 'fp_0.5': 13726, 'fn_0.5': 23095, 'tp_0.5': 45306, 'mcc_0.5': 0.6593590459063141, 'tn_0.95': 240700, 'fp_0.95': 92017, 'fn_0.95': 1385, 'tp_0.95': 67016, 'mcc_0.95': 0.5406465886579682, 'AUC': 0.9508239387571288, 'brier_loss': 0.06451902008145924, 'logloss': 0.20475075700211232, 'average_precision': 0.9888701410321303, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134742, 'fp_0.5': 7261, 'fn_0.5': 5476, 'tp_0.5': 23877, 'mcc_0.5': 0.7448343355402387, 'tn_0.95': 116844, 'fp_0.95': 25159, 'fn_0.95': 404, 'tp_0.95': 28949, 'mcc_0.95': 0.6558046965241416, 'AUC': 0.9704484542404831, 'brier_loss': 0.05173343052032262, 'logloss': 0.16267648181556435, 'average_precision': 0.9939971733571182, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316350, 'fp_0.5': 16367, 'fn_0.5': 12097, 'tp_0.5': 56304, 'mcc_0.5': 0.7557368496419348, 'tn_0.95': 275131, 'fp_0.95': 57586, 'fn_0.95': 428, 'tp_0.95': 67973, 'mcc_0.95': 0.6655846264884329, 'AUC': 0.9739179451113467, 'brier_loss': 0.04909179343751528, 'logloss': 0.15253905727727177, 'average_precision': 0.9948057974488969, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Program = fasttree
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_standard_fasttree_boot_support', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 20
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/fasttree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 132843, 'fp_0.5': 7483, 'fn_0.5': 6225, 'tp_0.5': 24805, 'mcc_0.5': 0.7346840712504508, 'tn_0.95': 112329, 'fp_0.95': 27997, 'fn_0.95': 841, 'tp_0.95': 30189, 'mcc_0.95': 0.6288973856766047, 'AUC': 0.9625698762481577, 'brier_loss': 0.057059540315034206, 'logloss': 0.1857082303754699, 'average_precision': 0.9912199144163168, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311582, 'fp_0.5': 16913, 'fn_0.5': 13919, 'tp_0.5': 58704, 'mcc_0.5': 0.7451211909801232, 'tn_0.95': 263649, 'fp_0.95': 64846, 'fn_0.95': 839, 'tp_0.95': 71784, 'mcc_0.95': 0.6427262348331823, 'AUC': 0.9694744978705122, 'brier_loss': 0.053625755917677424, 'logloss': 0.17024611263182035, 'average_precision': 0.9933209407948693, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 20
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/fasttree/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 132843, 'fp_0.5': 7483, 'fn_0.5': 6225, 'tp_0.5': 24805, 'mcc_0.5': 0.7346840712504508, 'tn_0.95': 112329, 'fp_0.95': 27997, 'fn_0.95': 841, 'tp_0.95': 30189, 'mcc_0.95': 0.6288973856766047, 'AUC': 0.9625698762481577, 'brier_loss': 0.057059540315034206, 'logloss': 0.1857082303754699, 'average_precision': 0.9912199144163168, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311582, 'fp_0.5': 16913, 'fn_0.5': 13919, 'tp_0.5': 58704, 'mcc_0.5': 0.7451211909801232, 'tn_0.95': 263649, 'fp_0.95': 64846, 'fn_0.95': 839, 'tp_0.95': 71784, 'mcc_0.95': 0.6427262348331823, 'AUC': 0.9694744978705122, 'brier_loss': 0.053625755917677424, 'logloss': 0.17024611263182035, 'average_precision': 0.9933209407948693, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/fasttree/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/fasttree/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 21 out of 21
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 140326, 'fp_0.5': 0, 'fn_0.5': 31030, 'tp_0.5': 0, 'mcc_0.5': 0.0, 'tn_0.95': 140326, 'fp_0.95': 0, 'fn_0.95': 31030, 'tp_0.95': 0, 'mcc_0.95': 0.0, 'AUC': 0.5, 'brier_loss': 0.18108499264688718, 'logloss': 6.254598864599649, 'average_precision': 0.8189150073531128, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 328495, 'fp_0.5': 0, 'fn_0.5': 72623, 'tp_0.5': 0, 'mcc_0.5': 0.0, 'tn_0.95': 328495, 'fp_0.95': 0, 'fn_0.95': 72623, 'tp_0.95': 0, 'mcc_0.95': 0.0, 'AUC': 0.5, 'brier_loss': 0.18105146116604093, 'logloss': 6.253440701468826, 'average_precision': 0.8189485388339591, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 140326, 'fp_0.5': 0, 'fn_0.5': 31030, 'tp_0.5': 0, 'mcc_0.5': 0.0, 'tn_0.95': 0, 'fp_0.95': 140326, 'fn_0.95': 0, 'tp_0.95': 31030, 'mcc_0.95': 0.0, 'AUC': 0.5, 'brier_loss': 0.1482932192093242, 'logloss': 0.47303473487578857, 'average_precision': 0.8189150073531128, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 328495, 'fp_0.5': 0, 'fn_0.5': 72623, 'tp_0.5': 0, 'mcc_0.5': 0.0, 'tn_0.95': 0, 'fp_0.95': 328495, 'fn_0.95': 0, 'tp_0.95': 72623, 'mcc_0.95': 0.0, 'AUC': 0.5, 'brier_loss': 0.14827182957568247, 'logloss': 0.47298412782561305, 'average_precision': 0.8189485388339591, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 132843, 'fp_0.5': 7483, 'fn_0.5': 6225, 'tp_0.5': 24805, 'mcc_0.5': 0.7346840712504508, 'tn_0.95': 112329, 'fp_0.95': 27997, 'fn_0.95': 841, 'tp_0.95': 30189, 'mcc_0.95': 0.6288973856766047, 'AUC': 0.9625698762481577, 'brier_loss': 0.057059540315034206, 'logloss': 0.1857082303754699, 'average_precision': 0.9912199144163168, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311582, 'fp_0.5': 16913, 'fn_0.5': 13919, 'tp_0.5': 58704, 'mcc_0.5': 0.7451211909801232, 'tn_0.95': 263649, 'fp_0.95': 64846, 'fn_0.95': 839, 'tp_0.95': 71784, 'mcc_0.95': 0.6427262348331823, 'AUC': 0.9694744978705122, 'brier_loss': 0.053625755917677424, 'logloss': 0.17024611263182035, 'average_precision': 0.9933209407948693, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Program = iqtree
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134559, 'fp_0.5': 7363, 'fn_0.5': 5698, 'tp_0.5': 23736, 'mcc_0.5': 0.7384016934382123, 'tn_0.95': 115966, 'fp_0.95': 25956, 'fn_0.95': 540, 'tp_0.95': 28894, 'mcc_0.95': 0.6458116772905071, 'AUC': 0.9679973172437328, 'brier_loss': 0.053090024612646274, 'logloss': 0.16918290392668112, 'average_precision': 0.9933204475771119, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315934, 'fp_0.5': 16526, 'fn_0.5': 12703, 'tp_0.5': 55955, 'mcc_0.5': 0.7491374355253194, 'tn_0.95': 272389, 'fp_0.95': 60071, 'fn_0.95': 480, 'tp_0.95': 68178, 'mcc_0.95': 0.6560540565636024, 'AUC': 0.9727632669769926, 'brier_loss': 0.050186186174245716, 'logloss': 0.15673429859919888, 'average_precision': 0.9945166902098895, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134559, 'fp_0.5': 7363, 'fn_0.5': 5698, 'tp_0.5': 23736, 'mcc_0.5': 0.7384016934382123, 'tn_0.95': 115966, 'fp_0.95': 25956, 'fn_0.95': 540, 'tp_0.95': 28894, 'mcc_0.95': 0.6458116772905071, 'AUC': 0.9679973172437328, 'brier_loss': 0.053090024612646274, 'logloss': 0.16918290392668112, 'average_precision': 0.9933204475771119, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315934, 'fp_0.5': 16526, 'fn_0.5': 12703, 'tp_0.5': 55955, 'mcc_0.5': 0.7491374355253194, 'tn_0.95': 272389, 'fp_0.95': 60071, 'fn_0.95': 480, 'tp_0.95': 68178, 'mcc_0.95': 0.6560540565636024, 'AUC': 0.9727632669769926, 'brier_loss': 0.050186186174245716, 'logloss': 0.1567342985991989, 'average_precision': 0.9945166902098895, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 140003, 'fp_0.5': 1919, 'fn_0.5': 16299, 'tp_0.5': 13135, 'mcc_0.5': 0.5765797833689706, 'tn_0.95': 120324, 'fp_0.95': 21598, 'fn_0.95': 3396, 'tp_0.95': 26038, 'mcc_0.95': 0.6166440934421157, 'AUC': 0.9330217849365996, 'brier_loss': 0.07580832885921708, 'logloss': 0.4079544491870929, 'average_precision': 0.9802857495185502, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 328094, 'fp_0.5': 4366, 'fn_0.5': 37486, 'tp_0.5': 31172, 'mcc_0.5': 0.5843915633389923, 'tn_0.95': 281870, 'fp_0.95': 50590, 'fn_0.95': 7891, 'tp_0.95': 60767, 'mcc_0.95': 0.6164258969810044, 'AUC': 0.9337417602238112, 'brier_loss': 0.07473375889389157, 'logloss': 0.40621606200976024, 'average_precision': 0.9804913008982211, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135675, 'fp_0.5': 6247, 'fn_0.5': 9443, 'tp_0.5': 19991, 'mcc_0.5': 0.6652868896228797, 'tn_0.95': 101191, 'fp_0.95': 40731, 'fn_0.95': 1562, 'tp_0.95': 27872, 'mcc_0.95': 0.5080223374290229, 'AUC': 0.9329541494242702, 'brier_loss': 0.06704999688107667, 'logloss': 0.22638812832531655, 'average_precision': 0.9802428621226617, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 318039, 'fp_0.5': 14421, 'fn_0.5': 21597, 'tp_0.5': 47061, 'mcc_0.5': 0.6712942091787137, 'tn_0.95': 237474, 'fp_0.95': 94986, 'fn_0.95': 3680, 'tp_0.95': 64978, 'mcc_0.95': 0.5082268097289823, 'AUC': 0.9337686153872756, 'brier_loss': 0.06609204233419816, 'logloss': 0.22399146328164196, 'average_precision': 0.980465293609326, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134473, 'fp_0.5': 7449, 'fn_0.5': 5445, 'tp_0.5': 23989, 'mcc_0.5': 0.7430847690577259, 'tn_0.95': 116943, 'fp_0.95': 24979, 'fn_0.95': 535, 'tp_0.95': 28899, 'mcc_0.95': 0.6546403839885598, 'AUC': 0.9689689075688983, 'brier_loss': 0.05240563872413522, 'logloss': 0.16668391817186928, 'average_precision': 0.9935486847901263, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315720, 'fp_0.5': 16740, 'fn_0.5': 12145, 'tp_0.5': 56513, 'mcc_0.5': 0.7533518939174298, 'tn_0.95': 274592, 'fp_0.95': 57868, 'fn_0.95': 482, 'tp_0.95': 68176, 'mcc_0.95': 0.6644628605452667, 'AUC': 0.9735755866597875, 'brier_loss': 0.049465252283107546, 'logloss': 0.15434309456738743, 'average_precision': 0.9946959080573292, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aLRT_iqtree_support
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 134747, 'fp_0.5': 7175, 'fn_0.5': 6861, 'tp_0.5': 22573, 'mcc_0.5': 0.7133451860353393, 'tn_0.95': 125852, 'fp_0.95': 16070, 'fn_0.95': 2629, 'tp_0.95': 26805, 'mcc_0.95': 0.6944350240494798, 'AUC': 0.9471022859396526, 'brier_loss': 0.06434866269182286, 'logloss': 0.4015620967262793, 'average_precision': 0.9848633151870705, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315724, 'fp_0.5': 16736, 'fn_0.5': 15775, 'tp_0.5': 52883, 'mcc_0.5': 0.7159477036505506, 'tn_0.95': 294889, 'fp_0.95': 37571, 'fn_0.95': 5799, 'tp_0.95': 62859, 'mcc_0.95': 0.6977279513086468, 'AUC': 0.9497259028345781, 'brier_loss': 0.06339707603961925, 'logloss': 0.37792485757452987, 'average_precision': 0.9859355841881249, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135026, 'fp_0.5': 6896, 'fn_0.5': 7157, 'tp_0.5': 22277, 'mcc_0.5': 0.7107636891915144, 'tn_0.95': 114277, 'fp_0.95': 27645, 'fn_0.95': 1213, 'tp_0.95': 28221, 'mcc_0.95': 0.6147469020684697, 'AUC': 0.9470403844698059, 'brier_loss': 0.060373407003225917, 'logloss': 0.201673116788213, 'average_precision': 0.9845882596477383, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316453, 'fp_0.5': 16007, 'fn_0.5': 16374, 'tp_0.5': 52284, 'mcc_0.5': 0.7148862427221206, 'tn_0.95': 267697, 'fp_0.95': 64763, 'fn_0.95': 2535, 'tp_0.95': 66123, 'mcc_0.95': 0.6171901168079329, 'AUC': 0.9498390883301526, 'brier_loss': 0.05921713145387346, 'logloss': 0.19711168043828803, 'average_precision': 0.9856998180307863, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134547, 'fp_0.5': 7375, 'fn_0.5': 5687, 'tp_0.5': 23747, 'mcc_0.5': 0.7384722221717691, 'tn_0.95': 116223, 'fp_0.95': 25699, 'fn_0.95': 556, 'tp_0.95': 28878, 'mcc_0.95': 0.6476936290209361, 'AUC': 0.968015189416056, 'brier_loss': 0.05312052271112426, 'logloss': 0.16917414166994338, 'average_precision': 0.9933336272340988, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315873, 'fp_0.5': 16587, 'fn_0.5': 12666, 'tp_0.5': 55992, 'mcc_0.5': 0.7490908936769347, 'tn_0.95': 272964, 'fp_0.95': 59496, 'fn_0.95': 481, 'tp_0.95': 68177, 'mcc_0.95': 0.6582261091216464, 'AUC': 0.9728449080810898, 'brier_loss': 0.050165606303705604, 'logloss': 0.15653234177137418, 'average_precision': 0.9945407998125757, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aBayes_iqtree_support
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 133591, 'fp_0.5': 8331, 'fn_0.5': 5937, 'tp_0.5': 23497, 'mcc_0.5': 0.7173103091682481, 'tn_0.95': 119799, 'fp_0.95': 22123, 'fn_0.95': 1632, 'tp_0.95': 27802, 'mcc_0.95': 0.6546699232601114, 'AUC': 0.9466305264696899, 'brier_loss': 0.06381099192021289, 'logloss': 0.33543675351780333, 'average_precision': 0.9842064009158841, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312941, 'fp_0.5': 19519, 'fn_0.5': 13608, 'tp_0.5': 55050, 'mcc_0.5': 0.7194539559226876, 'tn_0.95': 280673, 'fp_0.95': 51787, 'fn_0.95': 3555, 'tp_0.95': 65103, 'mcc_0.95': 0.6568503084783186, 'AUC': 0.948936982941273, 'brier_loss': 0.0629768449790336, 'logloss': 0.3166169252453231, 'average_precision': 0.9851595090273626, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135035, 'fp_0.5': 6887, 'fn_0.5': 7273, 'tp_0.5': 22161, 'mcc_0.5': 0.708080449206778, 'tn_0.95': 112768, 'fp_0.95': 29154, 'fn_0.95': 1104, 'tp_0.95': 28330, 'mcc_0.95': 0.6047882998557575, 'AUC': 0.9465212145969868, 'brier_loss': 0.060906081378940165, 'logloss': 0.20273258734358163, 'average_precision': 0.9841398744968903, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316429, 'fp_0.5': 16031, 'fn_0.5': 16506, 'tp_0.5': 52152, 'mcc_0.5': 0.713335877745869, 'tn_0.95': 264115, 'fp_0.95': 68345, 'fn_0.95': 2275, 'tp_0.95': 66383, 'mcc_0.95': 0.6071250658354199, 'AUC': 0.9491109449263405, 'brier_loss': 0.059771029326519426, 'logloss': 0.1982456989151873, 'average_precision': 0.98515268854034, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134588, 'fp_0.5': 7334, 'fn_0.5': 5704, 'tp_0.5': 23730, 'mcc_0.5': 0.7387258728742426, 'tn_0.95': 116263, 'fp_0.95': 25659, 'fn_0.95': 558, 'tp_0.95': 28876, 'mcc_0.95': 0.6479997074622573, 'AUC': 0.9679275194661873, 'brier_loss': 0.05312441965721105, 'logloss': 0.16935712116073331, 'average_precision': 0.993296130626879, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315929, 'fp_0.5': 16531, 'fn_0.5': 12758, 'tp_0.5': 55900, 'mcc_0.5': 0.7485398403428389, 'tn_0.95': 273224, 'fp_0.95': 59236, 'fn_0.95': 490, 'tp_0.95': 68168, 'mcc_0.95': 0.6591234267584959, 'AUC': 0.9727936610593706, 'brier_loss': 0.050219921668431464, 'logloss': 0.15675045823129857, 'average_precision': 0.9945333035358767, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Program = raxml
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_all_ML_boot_raxml', 'feature_mean_all_ML_boot_raxml_binary', 'feature_mean_all_ML_boot_raxml_neighbors', 'feature_mean_all_ML_boot_raxml_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 23
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 23 out of 23
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134744, 'fp_0.5': 7259, 'fn_0.5': 5571, 'tp_0.5': 23782, 'mcc_0.5': 0.7425869612721591, 'tn_0.95': 117014, 'fp_0.95': 24989, 'fn_0.95': 475, 'tp_0.95': 28878, 'mcc_0.95': 0.6556041782420439, 'AUC': 0.9694796235991486, 'brier_loss': 0.05236415665144898, 'logloss': 0.16535303554461558, 'average_precision': 0.9937603689907011, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316320, 'fp_0.5': 16397, 'fn_0.5': 12533, 'tp_0.5': 55868, 'mcc_0.5': 0.7510628681120258, 'tn_0.95': 275249, 'fp_0.95': 57468, 'fn_0.95': 500, 'tp_0.95': 67901, 'mcc_0.95': 0.6652929718889221, 'AUC': 0.9732706428709277, 'brier_loss': 0.04970529950570415, 'logloss': 0.15470794096672524, 'average_precision': 0.9946655922450813, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 23
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 23 out of 23
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134744, 'fp_0.5': 7259, 'fn_0.5': 5571, 'tp_0.5': 23782, 'mcc_0.5': 0.7425869612721591, 'tn_0.95': 117014, 'fp_0.95': 24989, 'fn_0.95': 475, 'tp_0.95': 28878, 'mcc_0.95': 0.6556041782420439, 'AUC': 0.9694796235991486, 'brier_loss': 0.05236415665144898, 'logloss': 0.16535303554461558, 'average_precision': 0.9937603689907011, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316320, 'fp_0.5': 16397, 'fn_0.5': 12533, 'tp_0.5': 55868, 'mcc_0.5': 0.7510628681120258, 'tn_0.95': 275249, 'fp_0.95': 57468, 'fn_0.95': 500, 'tp_0.95': 67901, 'mcc_0.95': 0.6652929718889221, 'AUC': 0.9732706428709277, 'brier_loss': 0.04970529950570415, 'logloss': 0.15470794096672524, 'average_precision': 0.9946655922450813, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 24 out of 24
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 136233, 'fp_0.5': 5770, 'fn_0.5': 10076, 'tp_0.5': 19277, 'mcc_0.5': 0.6570688289528165, 'tn_0.95': 96612, 'fp_0.95': 45391, 'fn_0.95': 381, 'tp_0.95': 28972, 'mcc_0.95': 0.5073343519403142, 'AUC': 0.9494182240845419, 'brier_loss': 0.06634679906160275, 'logloss': 0.2263965218592486, 'average_precision': 0.9885591489157667, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 318991, 'fp_0.5': 13726, 'fn_0.5': 23095, 'tp_0.5': 45306, 'mcc_0.5': 0.6593590459063141, 'tn_0.95': 226680, 'fp_0.95': 106037, 'fn_0.95': 858, 'tp_0.95': 67543, 'mcc_0.95': 0.5076444389002933, 'AUC': 0.9507938093647492, 'brier_loss': 0.06550648362825902, 'logloss': 0.22152280155772772, 'average_precision': 0.988979408745456, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 136233, 'fp_0.5': 5770, 'fn_0.5': 10076, 'tp_0.5': 19277, 'mcc_0.5': 0.6570688289528165, 'tn_0.95': 102534, 'fp_0.95': 39469, 'fn_0.95': 638, 'tp_0.95': 28715, 'mcc_0.95': 0.53907502649989, 'AUC': 0.9493700846422868, 'brier_loss': 0.06546485280421822, 'logloss': 0.2082439616708939, 'average_precision': 0.9884275387566983, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 318991, 'fp_0.5': 13726, 'fn_0.5': 23095, 'tp_0.5': 45306, 'mcc_0.5': 0.6593590459063141, 'tn_0.95': 240700, 'fp_0.95': 92017, 'fn_0.95': 1385, 'tp_0.95': 67016, 'mcc_0.95': 0.5406465886579682, 'AUC': 0.9508239387571288, 'brier_loss': 0.06451902008145924, 'logloss': 0.20475075700211232, 'average_precision': 0.9888701410321303, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134742, 'fp_0.5': 7261, 'fn_0.5': 5476, 'tp_0.5': 23877, 'mcc_0.5': 0.7448343355402387, 'tn_0.95': 116844, 'fp_0.95': 25159, 'fn_0.95': 404, 'tp_0.95': 28949, 'mcc_0.95': 0.6558046965241416, 'AUC': 0.9704484542404831, 'brier_loss': 0.05173343052032262, 'logloss': 0.16267648181556435, 'average_precision': 0.9939971733571182, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316350, 'fp_0.5': 16367, 'fn_0.5': 12097, 'tp_0.5': 56304, 'mcc_0.5': 0.7557368496419348, 'tn_0.95': 275131, 'fp_0.95': 57586, 'fn_0.95': 428, 'tp_0.95': 67973, 'mcc_0.95': 0.6655846264884329, 'AUC': 0.9739179451113467, 'brier_loss': 0.04909179343751528, 'logloss': 0.15253905727727177, 'average_precision': 0.9948057974488969, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Program = fasttree
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_standard_fasttree_boot_support', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 20
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/fasttree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 132843, 'fp_0.5': 7483, 'fn_0.5': 6225, 'tp_0.5': 24805, 'mcc_0.5': 0.7346840712504508, 'tn_0.95': 112329, 'fp_0.95': 27997, 'fn_0.95': 841, 'tp_0.95': 30189, 'mcc_0.95': 0.6288973856766047, 'AUC': 0.9625698762481577, 'brier_loss': 0.057059540315034206, 'logloss': 0.1857082303754699, 'average_precision': 0.9912199144163168, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311582, 'fp_0.5': 16913, 'fn_0.5': 13919, 'tp_0.5': 58704, 'mcc_0.5': 0.7451211909801232, 'tn_0.95': 263649, 'fp_0.95': 64846, 'fn_0.95': 839, 'tp_0.95': 71784, 'mcc_0.95': 0.6427262348331823, 'AUC': 0.9694744978705122, 'brier_loss': 0.053625755917677424, 'logloss': 0.17024611263182035, 'average_precision': 0.9933209407948693, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 20
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/fasttree/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 132843, 'fp_0.5': 7483, 'fn_0.5': 6225, 'tp_0.5': 24805, 'mcc_0.5': 0.7346840712504508, 'tn_0.95': 112329, 'fp_0.95': 27997, 'fn_0.95': 841, 'tp_0.95': 30189, 'mcc_0.95': 0.6288973856766047, 'AUC': 0.9625698762481577, 'brier_loss': 0.057059540315034206, 'logloss': 0.1857082303754699, 'average_precision': 0.9912199144163168, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311582, 'fp_0.5': 16913, 'fn_0.5': 13919, 'tp_0.5': 58704, 'mcc_0.5': 0.7451211909801232, 'tn_0.95': 263649, 'fp_0.95': 64846, 'fn_0.95': 839, 'tp_0.95': 71784, 'mcc_0.95': 0.6427262348331823, 'AUC': 0.9694744978705122, 'brier_loss': 0.053625755917677424, 'logloss': 0.17024611263182035, 'average_precision': 0.9933209407948693, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/fasttree/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/fasttree/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 21 out of 21
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 140326, 'fp_0.5': 0, 'fn_0.5': 31030, 'tp_0.5': 0, 'mcc_0.5': 0.0, 'tn_0.95': 140326, 'fp_0.95': 0, 'fn_0.95': 31030, 'tp_0.95': 0, 'mcc_0.95': 0.0, 'AUC': 0.5, 'brier_loss': 0.18108499264688718, 'logloss': 6.254598864599649, 'average_precision': 0.8189150073531128, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 328495, 'fp_0.5': 0, 'fn_0.5': 72623, 'tp_0.5': 0, 'mcc_0.5': 0.0, 'tn_0.95': 328495, 'fp_0.95': 0, 'fn_0.95': 72623, 'tp_0.95': 0, 'mcc_0.95': 0.0, 'AUC': 0.5, 'brier_loss': 0.18105146116604093, 'logloss': 6.253440701468826, 'average_precision': 0.8189485388339591, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 140326, 'fp_0.5': 0, 'fn_0.5': 31030, 'tp_0.5': 0, 'mcc_0.5': 0.0, 'tn_0.95': 0, 'fp_0.95': 140326, 'fn_0.95': 0, 'tp_0.95': 31030, 'mcc_0.95': 0.0, 'AUC': 0.5, 'brier_loss': 0.1482932192093242, 'logloss': 0.47303473487578857, 'average_precision': 0.8189150073531128, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 328495, 'fp_0.5': 0, 'fn_0.5': 72623, 'tp_0.5': 0, 'mcc_0.5': 0.0, 'tn_0.95': 0, 'fp_0.95': 328495, 'fn_0.95': 0, 'tp_0.95': 72623, 'mcc_0.95': 0.0, 'AUC': 0.5, 'brier_loss': 0.14827182957568247, 'logloss': 0.47298412782561305, 'average_precision': 0.8189485388339591, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 132843, 'fp_0.5': 7483, 'fn_0.5': 6225, 'tp_0.5': 24805, 'mcc_0.5': 0.7346840712504508, 'tn_0.95': 112329, 'fp_0.95': 27997, 'fn_0.95': 841, 'tp_0.95': 30189, 'mcc_0.95': 0.6288973856766047, 'AUC': 0.9625698762481577, 'brier_loss': 0.057059540315034206, 'logloss': 0.1857082303754699, 'average_precision': 0.9912199144163168, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311582, 'fp_0.5': 16913, 'fn_0.5': 13919, 'tp_0.5': 58704, 'mcc_0.5': 0.7451211909801232, 'tn_0.95': 263649, 'fp_0.95': 64846, 'fn_0.95': 839, 'tp_0.95': 71784, 'mcc_0.95': 0.6427262348331823, 'AUC': 0.9694744978705122, 'brier_loss': 0.053625755917677424, 'logloss': 0.17024611263182035, 'average_precision': 0.9933209407948693, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6094
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6094
INFO:root:Program = iqtree
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6094
INFO:root:Program = iqtree
INFO:root:Number of trees in main data is 6094
INFO:root:Generating optimized final model
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6000
INFO:root:Program = iqtree
INFO:root:Number of trees in main data is 6000
INFO:root:Generating optimized final model
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6000
INFO:root:Program = iqtree
INFO:root:Number of trees in main data is 6000
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6000
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4610
INFO:root:Number of MSAs in test data is 1975
INFO:root:Number of different trees is 6000
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 129964, 'fp_0.5': 6994, 'fn_0.5': 5556, 'tp_0.5': 22737, 'mcc_0.5': 0.7380191669381108, 'tn_0.95': 112191, 'fp_0.95': 24767, 'fn_0.95': 506, 'tp_0.95': 27787, 'mcc_0.95': 0.6481238998600156, 'AUC': 0.9684021862538899, 'brier_loss': 0.05282915547008909, 'logloss': 0.1680662309592613, 'average_precision': 0.9934366885648686, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311985, 'fp_0.5': 16313, 'fn_0.5': 12681, 'tp_0.5': 55414, 'mcc_0.5': 0.748641356896232, 'tn_0.95': 269533, 'fp_0.95': 58765, 'fn_0.95': 557, 'tp_0.95': 67538, 'mcc_0.95': 0.6579997324702813, 'AUC': 0.9726751461330643, 'brier_loss': 0.05029198985802741, 'logloss': 0.1572164038168358, 'average_precision': 0.9944839850684248, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 19
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6000
INFO:root:Program = iqtree
INFO:root:Number of trees in main data is 6000
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6000
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4610
INFO:root:Number of MSAs in test data is 1975
INFO:root:Number of different trees is 6000
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Using existing model in /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 129964, 'fp_0.5': 6994, 'fn_0.5': 5556, 'tp_0.5': 22737, 'mcc_0.5': 0.7380191669381108, 'tn_0.95': 112191, 'fp_0.95': 24767, 'fn_0.95': 506, 'tp_0.95': 27787, 'mcc_0.95': 0.6481238998600156, 'AUC': 0.9684021862538899, 'brier_loss': 0.05282915547008909, 'logloss': 0.1680662309592613, 'average_precision': 0.9934366885648686, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311985, 'fp_0.5': 16313, 'fn_0.5': 12681, 'tp_0.5': 55414, 'mcc_0.5': 0.748641356896232, 'tn_0.95': 269533, 'fp_0.95': 58765, 'fn_0.95': 557, 'tp_0.95': 67538, 'mcc_0.95': 0.6579997324702813, 'AUC': 0.9726751461330643, 'brier_loss': 0.05029198985802741, 'logloss': 0.1572164038168358, 'average_precision': 0.9944839850684248, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 129964, 'fp_0.5': 6994, 'fn_0.5': 5556, 'tp_0.5': 22737, 'mcc_0.5': 0.7380191669381108, 'tn_0.95': 112191, 'fp_0.95': 24767, 'fn_0.95': 506, 'tp_0.95': 27787, 'mcc_0.95': 0.6481238998600156, 'AUC': 0.9684021862538899, 'brier_loss': 0.05282915547008909, 'logloss': 0.1680662309592613, 'average_precision': 0.9934366885648686, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311985, 'fp_0.5': 16313, 'fn_0.5': 12681, 'tp_0.5': 55414, 'mcc_0.5': 0.748641356896232, 'tn_0.95': 269533, 'fp_0.95': 58765, 'fn_0.95': 557, 'tp_0.95': 67538, 'mcc_0.95': 0.6579997324702813, 'AUC': 0.9726751461330643, 'brier_loss': 0.05029198985802741, 'logloss': 0.1572164038168358, 'average_precision': 0.9944839850684248, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 135083, 'fp_0.5': 1875, 'fn_0.5': 15564, 'tp_0.5': 12729, 'mcc_0.5': 0.5789107425526795, 'tn_0.95': 115797, 'fp_0.95': 21161, 'fn_0.95': 3101, 'tp_0.95': 25192, 'mcc_0.95': 0.6170491047683538, 'AUC': 0.93540722332235, 'brier_loss': 0.07479911286467253, 'logloss': 0.3881290858255085, 'average_precision': 0.9813050413156179, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 323995, 'fp_0.5': 4303, 'fn_0.5': 37194, 'tp_0.5': 30901, 'mcc_0.5': 0.5843287155370502, 'tn_0.95': 278506, 'fp_0.95': 49792, 'fn_0.95': 7953, 'tp_0.95': 60142, 'mcc_0.95': 0.6163574887248974, 'AUC': 0.9328597702615664, 'brier_loss': 0.07515817761665826, 'logloss': 0.41418515965015396, 'average_precision': 0.9800564761352756, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 131157, 'fp_0.5': 5801, 'fn_0.5': 9055, 'tp_0.5': 19238, 'mcc_0.5': 0.6698545503323287, 'tn_0.95': 96942, 'fp_0.95': 40016, 'fn_0.95': 1399, 'tp_0.95': 26894, 'mcc_0.95': 0.5052360754437728, 'AUC': 0.9353747024092057, 'brier_loss': 0.06604130458993909, 'logloss': 0.22364682558653298, 'average_precision': 0.9812656597500522, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 314642, 'fp_0.5': 13656, 'fn_0.5': 22241, 'tp_0.5': 45854, 'mcc_0.5': 0.6671561501295108, 'tn_0.95': 234969, 'fp_0.95': 93329, 'fn_0.95': 3731, 'tp_0.95': 64364, 'mcc_0.95': 0.5093463115650242, 'AUC': 0.9328705544540156, 'brier_loss': 0.06653746042731631, 'logloss': 0.22541987711125133, 'average_precision': 0.9800268051666645, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 129949, 'fp_0.5': 7009, 'fn_0.5': 5328, 'tp_0.5': 22965, 'mcc_0.5': 0.7434521067985073, 'tn_0.95': 112816, 'fp_0.95': 24142, 'fn_0.95': 469, 'tp_0.95': 27824, 'mcc_0.95': 0.6548500172383502, 'AUC': 0.9692710736354605, 'brier_loss': 0.05220252907261842, 'logloss': 0.16574856181056072, 'average_precision': 0.9936416524690852, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311947, 'fp_0.5': 16351, 'fn_0.5': 12175, 'tp_0.5': 55920, 'mcc_0.5': 0.7535902171318064, 'tn_0.95': 270730, 'fp_0.95': 57568, 'fn_0.95': 514, 'tp_0.95': 67581, 'mcc_0.95': 0.6630901295178014, 'AUC': 0.9734636359723915, 'brier_loss': 0.04960756469953007, 'logloss': 0.1549713282686565, 'average_precision': 0.9946490532099068, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aLRT_iqtree_support
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 130076, 'fp_0.5': 6882, 'fn_0.5': 6631, 'tp_0.5': 21662, 'mcc_0.5': 0.7128833554839079, 'tn_0.95': 121517, 'fp_0.95': 15441, 'fn_0.95': 2488, 'tp_0.95': 25805, 'mcc_0.95': 0.6957346224146218, 'AUC': 0.9483632217472433, 'brier_loss': 0.06399071183938371, 'logloss': 0.39341839928602407, 'average_precision': 0.9854292859443893, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311741, 'fp_0.5': 16557, 'fn_0.5': 15621, 'tp_0.5': 52474, 'mcc_0.5': 0.7162898018405182, 'tn_0.95': 291079, 'fp_0.95': 37219, 'fn_0.95': 5803, 'tp_0.95': 62292, 'mcc_0.95': 0.697139502330187, 'AUC': 0.9491615964758799, 'brier_loss': 0.06359134949562682, 'logloss': 0.3823089399840767, 'average_precision': 0.9856403936260129, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130331, 'fp_0.5': 6627, 'fn_0.5': 6889, 'tp_0.5': 21404, 'mcc_0.5': 0.7107472644638526, 'tn_0.95': 108063, 'fp_0.95': 28895, 'fn_0.95': 970, 'tp_0.95': 27323, 'mcc_0.95': 0.6000856076670587, 'AUC': 0.9483509777268007, 'brier_loss': 0.05990427040140975, 'logloss': 0.19951233968841997, 'average_precision': 0.9851948811753569, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312453, 'fp_0.5': 15845, 'fn_0.5': 16231, 'tp_0.5': 51864, 'mcc_0.5': 0.7149880886328334, 'tn_0.95': 258622, 'fp_0.95': 69676, 'fn_0.95': 2296, 'tp_0.95': 65799, 'mcc_0.95': 0.5996658937671533, 'AUC': 0.9492893881644751, 'brier_loss': 0.05945414894720727, 'logloss': 0.1982238913492409, 'average_precision': 0.985439867155371, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 129928, 'fp_0.5': 7030, 'fn_0.5': 5490, 'tp_0.5': 22803, 'mcc_0.5': 0.7390610251149577, 'tn_0.95': 112219, 'fp_0.95': 24739, 'fn_0.95': 492, 'tp_0.95': 27801, 'mcc_0.95': 0.6487356341461193, 'AUC': 0.9684980965860535, 'brier_loss': 0.05276952449943423, 'logloss': 0.16787352633745886, 'average_precision': 0.9934529288737244, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311834, 'fp_0.5': 16464, 'fn_0.5': 12514, 'tp_0.5': 55581, 'mcc_0.5': 0.7493022831669537, 'tn_0.95': 269587, 'fp_0.95': 58711, 'fn_0.95': 547, 'tp_0.95': 67548, 'mcc_0.95': 0.6583128357257201, 'AUC': 0.9727442463900657, 'brier_loss': 0.05025290845731836, 'logloss': 0.1570691151794595, 'average_precision': 0.9944979246372632, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aBayes_iqtree_support
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 128956, 'fp_0.5': 8002, 'fn_0.5': 5717, 'tp_0.5': 22576, 'mcc_0.5': 0.7173514601535188, 'tn_0.95': 115652, 'fp_0.95': 21306, 'fn_0.95': 1511, 'tp_0.95': 26782, 'mcc_0.95': 0.6560120282455217, 'AUC': 0.9481598612001018, 'brier_loss': 0.06339976326315727, 'logloss': 0.3211869935234111, 'average_precision': 0.984900269230206, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 308983, 'fp_0.5': 19315, 'fn_0.5': 13496, 'tp_0.5': 54599, 'mcc_0.5': 0.7195325273390639, 'tn_0.95': 277073, 'fp_0.95': 51225, 'fn_0.95': 3597, 'tp_0.95': 64498, 'mcc_0.95': 0.6563565516965674, 'AUC': 0.9482726073503454, 'brier_loss': 0.06324197008395709, 'logloss': 0.32325010507673385, 'average_precision': 0.9848267904307906, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130163, 'fp_0.5': 6795, 'fn_0.5': 6760, 'tp_0.5': 21533, 'mcc_0.5': 0.7111091132809816, 'tn_0.95': 109416, 'fp_0.95': 27542, 'fn_0.95': 1018, 'tp_0.95': 27275, 'mcc_0.95': 0.610385017202345, 'AUC': 0.9482140378614904, 'brier_loss': 0.06035618333305725, 'logloss': 0.20017676387954375, 'average_precision': 0.984815310056951, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312033, 'fp_0.5': 16265, 'fn_0.5': 15980, 'tp_0.5': 52115, 'mcc_0.5': 0.714601481916218, 'tn_0.95': 261954, 'fp_0.95': 66344, 'fn_0.95': 2420, 'tp_0.95': 65675, 'mcc_0.95': 0.6101459993767432, 'AUC': 0.9483875314621178, 'brier_loss': 0.06004984463867493, 'logloss': 0.1995510255404213, 'average_precision': 0.9847465874445948, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 129880, 'fp_0.5': 7078, 'fn_0.5': 5424, 'tp_0.5': 22869, 'mcc_0.5': 0.7399021533640049, 'tn_0.95': 111993, 'fp_0.95': 24965, 'fn_0.95': 487, 'tp_0.95': 27806, 'mcc_0.95': 0.6467880555391906, 'AUC': 0.9684251358243807, 'brier_loss': 0.052792585716633846, 'logloss': 0.16798958376610637, 'average_precision': 0.9934293695264529, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311748, 'fp_0.5': 16550, 'fn_0.5': 12419, 'tp_0.5': 55676, 'mcc_0.5': 0.7496789648759943, 'tn_0.95': 269131, 'fp_0.95': 59167, 'fn_0.95': 508, 'tp_0.95': 67587, 'mcc_0.95': 0.6569688073968377, 'AUC': 0.9727504056704993, 'brier_loss': 0.050262369219731144, 'logloss': 0.15700231031961678, 'average_precision': 0.9945046963893643, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6000
INFO:root:Program = iqtree
INFO:root:Number of trees in main data is 6000
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6000
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4610
INFO:root:Number of MSAs in test data is 1975
INFO:root:Number of different trees is 6000
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6000
INFO:root:Program = iqtree
INFO:root:Number of trees in main data is 6000
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6000
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4610
INFO:root:Number of MSAs in test data is 1975
INFO:root:Number of different trees is 6000
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Using existing model in /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 129591, 'fp_0.5': 7367, 'fn_0.5': 7675, 'tp_0.5': 20618, 'mcc_0.5': 0.6778834724440268, 'tn_0.95': 103984, 'fp_0.95': 32974, 'fn_0.95': 867, 'tp_0.95': 27426, 'mcc_0.95': 0.5699220865605219, 'AUC': 0.9495632619457213, 'brier_loss': 0.06421392904228039, 'logloss': 0.20769195082171665, 'average_precision': 0.9882917917984907, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 310737, 'fp_0.5': 17561, 'fn_0.5': 17884, 'tp_0.5': 50211, 'mcc_0.5': 0.6851666386309124, 'tn_0.95': 248650, 'fp_0.95': 79648, 'fn_0.95': 1904, 'tp_0.95': 66191, 'mcc_0.95': 0.5705424593006282, 'AUC': 0.9515075957772021, 'brier_loss': 0.06303460894406257, 'logloss': 0.2041186800158708, 'average_precision': 0.9887209906991301, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 129591, 'fp_0.5': 7367, 'fn_0.5': 7675, 'tp_0.5': 20618, 'mcc_0.5': 0.6778834724440268, 'tn_0.95': 103984, 'fp_0.95': 32974, 'fn_0.95': 867, 'tp_0.95': 27426, 'mcc_0.95': 0.5699220865605219, 'AUC': 0.9495632619457213, 'brier_loss': 0.06421392904228039, 'logloss': 0.20769195082171665, 'average_precision': 0.9882917917984907, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 310737, 'fp_0.5': 17561, 'fn_0.5': 17884, 'tp_0.5': 50211, 'mcc_0.5': 0.6851666386309124, 'tn_0.95': 248650, 'fp_0.95': 79648, 'fn_0.95': 1904, 'tp_0.95': 66191, 'mcc_0.95': 0.5705424593006282, 'AUC': 0.9515075957772021, 'brier_loss': 0.06303460894406257, 'logloss': 0.2041186800158708, 'average_precision': 0.9887209906991301, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 135083, 'fp_0.5': 1875, 'fn_0.5': 15564, 'tp_0.5': 12729, 'mcc_0.5': 0.5789107425526795, 'tn_0.95': 115797, 'fp_0.95': 21161, 'fn_0.95': 3101, 'tp_0.95': 25192, 'mcc_0.95': 0.6170491047683538, 'AUC': 0.93540722332235, 'brier_loss': 0.07479911286467253, 'logloss': 0.3881290858255085, 'average_precision': 0.9813050413156179, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 323995, 'fp_0.5': 4303, 'fn_0.5': 37194, 'tp_0.5': 30901, 'mcc_0.5': 0.5843287155370502, 'tn_0.95': 278506, 'fp_0.95': 49792, 'fn_0.95': 7953, 'tp_0.95': 60142, 'mcc_0.95': 0.6163574887248974, 'AUC': 0.9328597702615664, 'brier_loss': 0.07515817761665826, 'logloss': 0.41418515965015396, 'average_precision': 0.9800564761352756, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130920, 'fp_0.5': 6038, 'fn_0.5': 8817, 'tp_0.5': 19476, 'mcc_0.5': 0.6716824087090763, 'tn_0.95': 96942, 'fp_0.95': 40016, 'fn_0.95': 1399, 'tp_0.95': 26894, 'mcc_0.95': 0.5052360754437728, 'AUC': 0.9354038769589169, 'brier_loss': 0.06601943703909599, 'logloss': 0.22357061354417385, 'average_precision': 0.9812936236343771, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 314025, 'fp_0.5': 14273, 'fn_0.5': 21609, 'tp_0.5': 46486, 'mcc_0.5': 0.6692404512476117, 'tn_0.95': 234969, 'fp_0.95': 93329, 'fn_0.95': 3731, 'tp_0.95': 64364, 'mcc_0.95': 0.5093463115650242, 'AUC': 0.9328620370911207, 'brier_loss': 0.06654157694876706, 'logloss': 0.2254328253092553, 'average_precision': 0.9800467811879479, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130755, 'fp_0.5': 6203, 'fn_0.5': 7565, 'tp_0.5': 20728, 'mcc_0.5': 0.701017054451303, 'tn_0.95': 102783, 'fp_0.95': 34175, 'fn_0.95': 635, 'tp_0.95': 27658, 'mcc_0.95': 0.566725300443164, 'AUC': 0.9564097541728596, 'brier_loss': 0.059656801998186924, 'logloss': 0.1946543542077259, 'average_precision': 0.9900263327353405, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 313407, 'fp_0.5': 14891, 'fn_0.5': 18055, 'tp_0.5': 50040, 'mcc_0.5': 0.7027187310777048, 'tn_0.95': 246562, 'fp_0.95': 81736, 'fn_0.95': 1468, 'tp_0.95': 66627, 'mcc_0.95': 0.5685727190390506, 'AUC': 0.9575027147370654, 'brier_loss': 0.05907349785758976, 'logloss': 0.19260010662062363, 'average_precision': 0.9902350474319305, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aLRT_iqtree_support
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 130076, 'fp_0.5': 6882, 'fn_0.5': 6631, 'tp_0.5': 21662, 'mcc_0.5': 0.7128833554839079, 'tn_0.95': 121517, 'fp_0.95': 15441, 'fn_0.95': 2488, 'tp_0.95': 25805, 'mcc_0.95': 0.6957346224146218, 'AUC': 0.9483632217472433, 'brier_loss': 0.06399071183938371, 'logloss': 0.39341839928602407, 'average_precision': 0.9854292859443893, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311741, 'fp_0.5': 16557, 'fn_0.5': 15621, 'tp_0.5': 52474, 'mcc_0.5': 0.7162898018405182, 'tn_0.95': 291079, 'fp_0.95': 37219, 'fn_0.95': 5803, 'tp_0.95': 62292, 'mcc_0.95': 0.697139502330187, 'AUC': 0.9491615964758799, 'brier_loss': 0.06359134949562682, 'logloss': 0.3823089399840767, 'average_precision': 0.9856403936260129, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130292, 'fp_0.5': 6666, 'fn_0.5': 6860, 'tp_0.5': 21433, 'mcc_0.5': 0.7108049483410305, 'tn_0.95': 109237, 'fp_0.95': 27721, 'fn_0.95': 1032, 'tp_0.95': 27261, 'mcc_0.95': 0.608483808613037, 'AUC': 0.9483645403439858, 'brier_loss': 0.059850851371996756, 'logloss': 0.19940897299615876, 'average_precision': 0.9853683634771595, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312313, 'fp_0.5': 15985, 'fn_0.5': 16168, 'tp_0.5': 51927, 'mcc_0.5': 0.7146385151473165, 'tn_0.95': 261421, 'fp_0.95': 66877, 'fn_0.95': 2443, 'tp_0.95': 65652, 'mcc_0.95': 0.6079909608575871, 'AUC': 0.9491856690373536, 'brier_loss': 0.05952376045099739, 'logloss': 0.19839342766967474, 'average_precision': 0.9855780824840665, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130268, 'fp_0.5': 6690, 'fn_0.5': 6496, 'tp_0.5': 21797, 'mcc_0.5': 0.719604180447423, 'tn_0.95': 107233, 'fp_0.95': 29725, 'fn_0.95': 833, 'tp_0.95': 27460, 'mcc_0.95': 0.5966818352265919, 'AUC': 0.9595848508699241, 'brier_loss': 0.05741267372551378, 'logloss': 0.1879442662938481, 'average_precision': 0.9910080862752805, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312317, 'fp_0.5': 15981, 'fn_0.5': 15083, 'tp_0.5': 53012, 'mcc_0.5': 0.7260507879697569, 'tn_0.95': 255835, 'fp_0.95': 72463, 'fn_0.95': 1794, 'tp_0.95': 66301, 'mcc_0.95': 0.5954033173238032, 'AUC': 0.9607525259237307, 'brier_loss': 0.056664985701854596, 'logloss': 0.18550079940606723, 'average_precision': 0.9912307543113514, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aBayes_iqtree_support
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 128956, 'fp_0.5': 8002, 'fn_0.5': 5717, 'tp_0.5': 22576, 'mcc_0.5': 0.7173514601535188, 'tn_0.95': 115652, 'fp_0.95': 21306, 'fn_0.95': 1511, 'tp_0.95': 26782, 'mcc_0.95': 0.6560120282455217, 'AUC': 0.9481598612001018, 'brier_loss': 0.06339976326315727, 'logloss': 0.3211869935234111, 'average_precision': 0.984900269230206, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 308983, 'fp_0.5': 19315, 'fn_0.5': 13496, 'tp_0.5': 54599, 'mcc_0.5': 0.7195325273390639, 'tn_0.95': 277073, 'fp_0.95': 51225, 'fn_0.95': 3597, 'tp_0.95': 64498, 'mcc_0.95': 0.6563565516965674, 'AUC': 0.9482726073503454, 'brier_loss': 0.06324197008395709, 'logloss': 0.32325010507673385, 'average_precision': 0.9848267904307906, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130333, 'fp_0.5': 6625, 'fn_0.5': 6924, 'tp_0.5': 21369, 'mcc_0.5': 0.7098933201721438, 'tn_0.95': 109003, 'fp_0.95': 27955, 'fn_0.95': 987, 'tp_0.95': 27306, 'mcc_0.95': 0.6076208582765106, 'AUC': 0.9481989961294738, 'brier_loss': 0.06031793500125864, 'logloss': 0.20005977076509965, 'average_precision': 0.9848115743843239, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312406, 'fp_0.5': 15892, 'fn_0.5': 16392, 'tp_0.5': 51703, 'mcc_0.5': 0.7129518400236157, 'tn_0.95': 260921, 'fp_0.95': 67377, 'fn_0.95': 2371, 'tp_0.95': 65724, 'mcc_0.95': 0.60696986553176, 'AUC': 0.9483093146371682, 'brier_loss': 0.06010137414406162, 'logloss': 0.1997034509728014, 'average_precision': 0.9847289838973998, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130118, 'fp_0.5': 6840, 'fn_0.5': 6440, 'tp_0.5': 21853, 'mcc_0.5': 0.71843612017053, 'tn_0.95': 109674, 'fp_0.95': 27284, 'fn_0.95': 721, 'tp_0.95': 27572, 'mcc_0.95': 0.6201796458882922, 'AUC': 0.9614564628798536, 'brier_loss': 0.056676726314689535, 'logloss': 0.18343682373589013, 'average_precision': 0.9913485461768842, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311858, 'fp_0.5': 16440, 'fn_0.5': 14947, 'tp_0.5': 53148, 'mcc_0.5': 0.7241919337625993, 'tn_0.95': 262825, 'fp_0.95': 65473, 'fn_0.95': 1643, 'tp_0.95': 66452, 'mcc_0.95': 0.621512258607618, 'AUC': 0.9626215629005093, 'brier_loss': 0.056108400686801424, 'logloss': 0.18129119424679574, 'average_precision': 0.9916985718803071, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6000
INFO:root:Program = iqtree
INFO:root:Number of trees in main data is 6000
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6000
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4610
INFO:root:Number of MSAs in test data is 1975
INFO:root:Number of different trees is 6000
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 129964, 'fp_0.5': 6994, 'fn_0.5': 5556, 'tp_0.5': 22737, 'mcc_0.5': 0.7380191669381108, 'tn_0.95': 112191, 'fp_0.95': 24767, 'fn_0.95': 506, 'tp_0.95': 27787, 'mcc_0.95': 0.6481238998600156, 'AUC': 0.9684021862538899, 'brier_loss': 0.05282915547008909, 'logloss': 0.1680662309592613, 'average_precision': 0.9934366885648686, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311985, 'fp_0.5': 16313, 'fn_0.5': 12681, 'tp_0.5': 55414, 'mcc_0.5': 0.748641356896232, 'tn_0.95': 269533, 'fp_0.95': 58765, 'fn_0.95': 557, 'tp_0.95': 67538, 'mcc_0.95': 0.6579997324702813, 'AUC': 0.9726751461330643, 'brier_loss': 0.05029198985802741, 'logloss': 0.1572164038168358, 'average_precision': 0.9944839850684248, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 19 out of 19
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 129964, 'fp_0.5': 6994, 'fn_0.5': 5556, 'tp_0.5': 22737, 'mcc_0.5': 0.7380191669381108, 'tn_0.95': 112191, 'fp_0.95': 24767, 'fn_0.95': 506, 'tp_0.95': 27787, 'mcc_0.95': 0.6481238998600156, 'AUC': 0.9684021862538899, 'brier_loss': 0.05282915547008909, 'logloss': 0.1680662309592613, 'average_precision': 0.9934366885648686, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311985, 'fp_0.5': 16313, 'fn_0.5': 12681, 'tp_0.5': 55414, 'mcc_0.5': 0.748641356896232, 'tn_0.95': 269533, 'fp_0.95': 58765, 'fn_0.95': 557, 'tp_0.95': 67538, 'mcc_0.95': 0.6579997324702813, 'AUC': 0.9726751461330643, 'brier_loss': 0.05029198985802741, 'logloss': 0.1572164038168358, 'average_precision': 0.9944839850684248, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 135083, 'fp_0.5': 1875, 'fn_0.5': 15564, 'tp_0.5': 12729, 'mcc_0.5': 0.5789107425526795, 'tn_0.95': 115797, 'fp_0.95': 21161, 'fn_0.95': 3101, 'tp_0.95': 25192, 'mcc_0.95': 0.6170491047683538, 'AUC': 0.93540722332235, 'brier_loss': 0.07479911286467253, 'logloss': 0.3881290858255085, 'average_precision': 0.9813050413156179, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 323995, 'fp_0.5': 4303, 'fn_0.5': 37194, 'tp_0.5': 30901, 'mcc_0.5': 0.5843287155370502, 'tn_0.95': 278506, 'fp_0.95': 49792, 'fn_0.95': 7953, 'tp_0.95': 60142, 'mcc_0.95': 0.6163574887248974, 'AUC': 0.9328597702615664, 'brier_loss': 0.07515817761665826, 'logloss': 0.41418515965015396, 'average_precision': 0.9800564761352756, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 131157, 'fp_0.5': 5801, 'fn_0.5': 9055, 'tp_0.5': 19238, 'mcc_0.5': 0.6698545503323287, 'tn_0.95': 96942, 'fp_0.95': 40016, 'fn_0.95': 1399, 'tp_0.95': 26894, 'mcc_0.95': 0.5052360754437728, 'AUC': 0.9353747024092057, 'brier_loss': 0.06604130458993909, 'logloss': 0.22364682558653298, 'average_precision': 0.9812656597500522, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 314642, 'fp_0.5': 13656, 'fn_0.5': 22241, 'tp_0.5': 45854, 'mcc_0.5': 0.6671561501295108, 'tn_0.95': 234969, 'fp_0.95': 93329, 'fn_0.95': 3731, 'tp_0.95': 64364, 'mcc_0.95': 0.5093463115650242, 'AUC': 0.9328705544540156, 'brier_loss': 0.06653746042731631, 'logloss': 0.22541987711125133, 'average_precision': 0.9800268051666645, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 129949, 'fp_0.5': 7009, 'fn_0.5': 5328, 'tp_0.5': 22965, 'mcc_0.5': 0.7434521067985073, 'tn_0.95': 112816, 'fp_0.95': 24142, 'fn_0.95': 469, 'tp_0.95': 27824, 'mcc_0.95': 0.6548500172383502, 'AUC': 0.9692710736354605, 'brier_loss': 0.05220252907261842, 'logloss': 0.16574856181056072, 'average_precision': 0.9936416524690852, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311947, 'fp_0.5': 16351, 'fn_0.5': 12175, 'tp_0.5': 55920, 'mcc_0.5': 0.7535902171318064, 'tn_0.95': 270730, 'fp_0.95': 57568, 'fn_0.95': 514, 'tp_0.95': 67581, 'mcc_0.95': 0.6630901295178014, 'AUC': 0.9734636359723915, 'brier_loss': 0.04960756469953007, 'logloss': 0.15497132826865653, 'average_precision': 0.9946490532099068, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aLRT_iqtree_support
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 130076, 'fp_0.5': 6882, 'fn_0.5': 6631, 'tp_0.5': 21662, 'mcc_0.5': 0.7128833554839079, 'tn_0.95': 121517, 'fp_0.95': 15441, 'fn_0.95': 2488, 'tp_0.95': 25805, 'mcc_0.95': 0.6957346224146218, 'AUC': 0.9483632217472433, 'brier_loss': 0.06399071183938371, 'logloss': 0.39341839928602407, 'average_precision': 0.9854292859443893, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311741, 'fp_0.5': 16557, 'fn_0.5': 15621, 'tp_0.5': 52474, 'mcc_0.5': 0.7162898018405182, 'tn_0.95': 291079, 'fp_0.95': 37219, 'fn_0.95': 5803, 'tp_0.95': 62292, 'mcc_0.95': 0.697139502330187, 'AUC': 0.9491615964758799, 'brier_loss': 0.06359134949562682, 'logloss': 0.3823089399840767, 'average_precision': 0.9856403936260129, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130331, 'fp_0.5': 6627, 'fn_0.5': 6889, 'tp_0.5': 21404, 'mcc_0.5': 0.7107472644638526, 'tn_0.95': 108063, 'fp_0.95': 28895, 'fn_0.95': 970, 'tp_0.95': 27323, 'mcc_0.95': 0.6000856076670587, 'AUC': 0.9483509777268007, 'brier_loss': 0.05990427040140975, 'logloss': 0.19951233968841997, 'average_precision': 0.9851948811753569, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312453, 'fp_0.5': 15845, 'fn_0.5': 16231, 'tp_0.5': 51864, 'mcc_0.5': 0.7149880886328334, 'tn_0.95': 258622, 'fp_0.95': 69676, 'fn_0.95': 2296, 'tp_0.95': 65799, 'mcc_0.95': 0.5996658937671533, 'AUC': 0.9492893881644751, 'brier_loss': 0.05945414894720727, 'logloss': 0.1982238913492409, 'average_precision': 0.985439867155371, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 129928, 'fp_0.5': 7030, 'fn_0.5': 5490, 'tp_0.5': 22803, 'mcc_0.5': 0.7390610251149577, 'tn_0.95': 112219, 'fp_0.95': 24739, 'fn_0.95': 492, 'tp_0.95': 27801, 'mcc_0.95': 0.6487356341461193, 'AUC': 0.9684980965860535, 'brier_loss': 0.05276952449943423, 'logloss': 0.16787352633745886, 'average_precision': 0.9934529288737244, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311834, 'fp_0.5': 16464, 'fn_0.5': 12514, 'tp_0.5': 55581, 'mcc_0.5': 0.7493022831669537, 'tn_0.95': 269587, 'fp_0.95': 58711, 'fn_0.95': 547, 'tp_0.95': 67548, 'mcc_0.95': 0.6583128357257201, 'AUC': 0.9727442463900657, 'brier_loss': 0.05025290845731836, 'logloss': 0.1570691151794595, 'average_precision': 0.9944979246372632, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aBayes_iqtree_support
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 20 out of 20
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 128956, 'fp_0.5': 8002, 'fn_0.5': 5717, 'tp_0.5': 22576, 'mcc_0.5': 0.7173514601535188, 'tn_0.95': 115652, 'fp_0.95': 21306, 'fn_0.95': 1511, 'tp_0.95': 26782, 'mcc_0.95': 0.6560120282455217, 'AUC': 0.9481598612001018, 'brier_loss': 0.06339976326315727, 'logloss': 0.3211869935234111, 'average_precision': 0.984900269230206, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 308983, 'fp_0.5': 19315, 'fn_0.5': 13496, 'tp_0.5': 54599, 'mcc_0.5': 0.7195325273390639, 'tn_0.95': 277073, 'fp_0.95': 51225, 'fn_0.95': 3597, 'tp_0.95': 64498, 'mcc_0.95': 0.6563565516965674, 'AUC': 0.9482726073503454, 'brier_loss': 0.06324197008395709, 'logloss': 0.32325010507673385, 'average_precision': 0.9848267904307906, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 130163, 'fp_0.5': 6795, 'fn_0.5': 6760, 'tp_0.5': 21533, 'mcc_0.5': 0.7111091132809816, 'tn_0.95': 109416, 'fp_0.95': 27542, 'fn_0.95': 1018, 'tp_0.95': 27275, 'mcc_0.95': 0.610385017202345, 'AUC': 0.9482140378614904, 'brier_loss': 0.06035618333305725, 'logloss': 0.20017676387954375, 'average_precision': 0.984815310056951, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312033, 'fp_0.5': 16265, 'fn_0.5': 15980, 'tp_0.5': 52115, 'mcc_0.5': 0.714601481916218, 'tn_0.95': 261954, 'fp_0.95': 66344, 'fn_0.95': 2420, 'tp_0.95': 65675, 'mcc_0.95': 0.6101459993767432, 'AUC': 0.9483875314621178, 'brier_loss': 0.06004984463867493, 'logloss': 0.1995510255404213, 'average_precision': 0.9847465874445948, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 129880, 'fp_0.5': 7078, 'fn_0.5': 5424, 'tp_0.5': 22869, 'mcc_0.5': 0.7399021533640049, 'tn_0.95': 111993, 'fp_0.95': 24965, 'fn_0.95': 487, 'tp_0.95': 27806, 'mcc_0.95': 0.6467880555391906, 'AUC': 0.9684251358243807, 'brier_loss': 0.052792585716633846, 'logloss': 0.16798958376610637, 'average_precision': 0.9934293695264529, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 311748, 'fp_0.5': 16550, 'fn_0.5': 12419, 'tp_0.5': 55676, 'mcc_0.5': 0.7496789648759943, 'tn_0.95': 269131, 'fp_0.95': 59167, 'fn_0.95': 508, 'tp_0.95': 67587, 'mcc_0.95': 0.6569688073968377, 'AUC': 0.9727504056704993, 'brier_loss': 0.050262369219731144, 'logloss': 0.15700231031961678, 'average_precision': 0.9945046963893643, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Program = raxml
INFO:root:Number of trees in main data is 6000
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6000
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4610
INFO:root:Number of MSAs in test data is 1975
INFO:root:Number of different trees is 6000
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_all_ML_boot_raxml', 'feature_mean_all_ML_boot_raxml_binary', 'feature_mean_all_ML_boot_raxml_neighbors', 'feature_mean_all_ML_boot_raxml_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 23
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 23 out of 23
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 129957, 'fp_0.5': 7056, 'fn_0.5': 5340, 'tp_0.5': 22898, 'mcc_0.5': 0.7419826084117775, 'tn_0.95': 113265, 'fp_0.95': 23748, 'fn_0.95': 445, 'tp_0.95': 27793, 'mcc_0.95': 0.6588660918899805, 'AUC': 0.9698487399199266, 'brier_loss': 0.052044442053244544, 'logloss': 0.16410329081002917, 'average_precision': 0.9938299326298778, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312077, 'fp_0.5': 16529, 'fn_0.5': 12233, 'tp_0.5': 55554, 'mcc_0.5': 0.7508871896267053, 'tn_0.95': 271676, 'fp_0.95': 56930, 'fn_0.95': 500, 'tp_0.95': 67287, 'mcc_0.95': 0.6650882428773119, 'AUC': 0.9730373380412676, 'brier_loss': 0.049976777274890104, 'logloss': 0.15552963742853318, 'average_precision': 0.9946043662285831, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 23
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 23 out of 23
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6000
INFO:root:Program = iqtree
INFO:root:Number of trees in main data is 6000
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6000
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4610
INFO:root:Number of MSAs in test data is 1975
INFO:root:Number of different trees is 6000
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Number of common tree IDS is 6000
INFO:root:Program = iqtree
INFO:root:Number of trees in main data is 6000
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6000
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4610
INFO:root:Number of MSAs in test data is 1975
INFO:root:Number of different trees is 6000
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 19
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
