INFO:root:Program = iqtree
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_min_ll_diff_norm', 'feature_max_ll_diff_norm', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty', 'feature_G', 'feature_I', 'feature_F', 'feature_free_parameters']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 25
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 25 out of 25
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134595, 'fp_0.5': 7327, 'fn_0.5': 5712, 'tp_0.5': 23722, 'mcc_0.5': 0.73864694309446, 'tn_0.9': 121771, 'fp_0.9': 20151, 'fn_0.9': 974, 'tp_0.9': 28460, 'mcc_0.9': 0.6902294881300323, 'tn_0.95': 116364, 'fp_0.95': 25558, 'fn_0.95': 561, 'tp_0.95': 28873, 'mcc_0.95': 0.6488239322808764, 'tn_0.99': 100204, 'fp_0.99': 41718, 'fn_0.99': 169, 'tp_0.99': 29265, 'mcc_0.99': 0.5362324018237945, 'AUC': 0.9681150974399366, 'logloss': 0.168926352697621, 'average_precision': 0.9933526365778704, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315960, 'fp_0.5': 16500, 'fn_0.5': 12713, 'tp_0.5': 55945, 'mcc_0.5': 0.7492164727512102, 'tn_0.9': 285760, 'fp_0.9': 46700, 'fn_0.9': 1291, 'tp_0.9': 67367, 'mcc_0.9': 0.7019587135989818, 'tn_0.95': 273147, 'fp_0.95': 59313, 'fn_0.95': 477, 'tp_0.95': 68181, 'mcc_0.95': 0.65896490868045, 'tn_0.99': 235486, 'fp_0.99': 96974, 'fn_0.99': 40, 'tp_0.99': 68618, 'mcc_0.99': 0.5414327261201193, 'AUC': 0.9728656886250402, 'logloss': 0.15648194716411495, 'average_precision': 0.9945537413296814, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 21
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 21 out of 21
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134979, 'fp_0.5': 6943, 'fn_0.5': 6444, 'tp_0.5': 22990, 'mcc_0.5': 0.7272996871508839, 'tn_0.9': 120327, 'fp_0.9': 21595, 'fn_0.9': 1231, 'tp_0.9': 28203, 'mcc_0.9': 0.6695696371924694, 'tn_0.95': 112945, 'fp_0.95': 28977, 'fn_0.95': 630, 'tp_0.95': 28804, 'mcc_0.95': 0.6178634832680955, 'tn_0.99': 94936, 'fp_0.99': 46986, 'fn_0.99': 201, 'tp_0.99': 29233, 'mcc_0.99': 0.5025370010605016, 'AUC': 0.9643625192525631, 'logloss': 0.17840513045767653, 'average_precision': 0.9924088427240045, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316955, 'fp_0.5': 15505, 'fn_0.5': 14607, 'tp_0.5': 54051, 'mcc_0.5': 0.7368120671293533, 'tn_0.9': 282786, 'fp_0.9': 49674, 'fn_0.9': 1786, 'tp_0.9': 66872, 'mcc_0.9': 0.6840689876230599, 'tn_0.95': 265588, 'fp_0.95': 66872, 'fn_0.95': 721, 'tp_0.95': 67937, 'mcc_0.95': 0.6286155355422911, 'tn_0.99': 223902, 'fp_0.99': 108558, 'fn_0.99': 115, 'tp_0.99': 68543, 'mcc_0.99': 0.5095671058609242, 'AUC': 0.9698637733360751, 'logloss': 0.16535504506590548, 'average_precision': 0.9938491809867274, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 26 out of 26
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 141921, 'fp_0.5': 1, 'fn_0.5': 29216, 'tp_0.5': 218, 'mcc_0.5': 0.07811767916265619, 'tn_0.9': 141921, 'fp_0.9': 1, 'fn_0.9': 29216, 'tp_0.9': 218, 'mcc_0.9': 0.07811767916265619, 'tn_0.95': 141921, 'fp_0.95': 1, 'fn_0.95': 29216, 'tp_0.95': 218, 'mcc_0.95': 0.07811767916265619, 'tn_0.99': 141921, 'fp_0.99': 1, 'fn_0.99': 29216, 'tp_0.99': 218, 'mcc_0.99': 0.07811767916265619, 'AUC': 0.9330217849365996, 'logloss': 5.889159358111919, 'average_precision': 0.9802857495185502, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 332458, 'fp_0.5': 2, 'fn_0.5': 68127, 'tp_0.5': 531, 'mcc_0.5': 0.07990422810782345, 'tn_0.9': 332458, 'fp_0.9': 2, 'fn_0.9': 68127, 'tp_0.9': 531, 'mcc_0.9': 0.07990422810782345, 'tn_0.95': 332458, 'fp_0.95': 2, 'fn_0.95': 68127, 'tp_0.95': 531, 'mcc_0.95': 0.07990422810782345, 'tn_0.99': 332458, 'fp_0.99': 2, 'fn_0.99': 68127, 'tp_0.99': 531, 'mcc_0.99': 0.07990422810782345, 'AUC': 0.9337417602238112, 'logloss': 5.866470143905277, 'average_precision': 0.9804913008982211, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135675, 'fp_0.5': 6247, 'fn_0.5': 9443, 'tp_0.5': 19991, 'mcc_0.5': 0.6652868896228797, 'tn_0.9': 113952, 'fp_0.9': 27970, 'fn_0.9': 2599, 'tp_0.9': 26835, 'mcc_0.9': 0.577905707406351, 'tn_0.95': 101191, 'fp_0.95': 40731, 'fn_0.95': 1562, 'tp_0.95': 27872, 'mcc_0.95': 0.5080223374290229, 'tn_0.99': 0, 'fp_0.99': 141922, 'fn_0.99': 0, 'tp_0.99': 29434, 'mcc_0.99': 0.0, 'AUC': 0.9329541494242702, 'logloss': 0.22638812832531655, 'average_precision': 0.9802428621226617, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 318039, 'fp_0.5': 14421, 'fn_0.5': 21597, 'tp_0.5': 47061, 'mcc_0.5': 0.6712942091787137, 'tn_0.9': 267159, 'fp_0.9': 65301, 'fn_0.9': 5980, 'tp_0.9': 62678, 'mcc_0.9': 0.5789760057549559, 'tn_0.95': 237474, 'fp_0.95': 94986, 'fn_0.95': 3680, 'tp_0.95': 64978, 'mcc_0.95': 0.5082268097289823, 'tn_0.99': 0, 'fp_0.99': 332460, 'fn_0.99': 0, 'tp_0.99': 68658, 'mcc_0.99': 0.0, 'AUC': 0.9337686153872756, 'logloss': 0.22399146328164196, 'average_precision': 0.980465293609326, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134498, 'fp_0.5': 7424, 'fn_0.5': 5432, 'tp_0.5': 24002, 'mcc_0.5': 0.7437969182310742, 'tn_0.9': 122459, 'fp_0.9': 19463, 'fn_0.9': 914, 'tp_0.9': 28520, 'mcc_0.9': 0.698745840115206, 'tn_0.95': 116546, 'fp_0.95': 25376, 'fn_0.95': 497, 'tp_0.95': 28937, 'mcc_0.95': 0.6520030227426281, 'tn_0.99': 101516, 'fp_0.99': 40406, 'fn_0.99': 154, 'tp_0.99': 29280, 'mcc_0.99': 0.5452262562334059, 'AUC': 0.9691304537366656, 'logloss': 0.1661516198214501, 'average_precision': 0.9935923982895418, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315796, 'fp_0.5': 16664, 'fn_0.5': 12143, 'tp_0.5': 56515, 'mcc_0.5': 0.7538990097887883, 'tn_0.9': 287347, 'fp_0.9': 45113, 'fn_0.9': 1325, 'tp_0.9': 67333, 'mcc_0.9': 0.708600097955685, 'tn_0.95': 273692, 'fp_0.95': 58768, 'fn_0.95': 451, 'tp_0.95': 68207, 'mcc_0.95': 0.6613190560701411, 'tn_0.99': 239056, 'fp_0.99': 93404, 'fn_0.99': 53, 'tp_0.99': 68605, 'mcc_0.99': 0.5513679279507009, 'AUC': 0.9735668754461254, 'logloss': 0.15431504025047202, 'average_precision': 0.9946880793355648, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 26 out of 26
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 134747, 'fp_0.5': 7175, 'fn_0.5': 6861, 'tp_0.5': 22573, 'mcc_0.5': 0.7133451860353393, 'tn_0.9': 128713, 'fp_0.9': 13209, 'fn_0.9': 3389, 'tp_0.9': 26045, 'mcc_0.9': 0.7106605369616977, 'tn_0.95': 125852, 'fp_0.95': 16070, 'fn_0.95': 2629, 'tp_0.95': 26805, 'mcc_0.95': 0.6944350240494798, 'tn_0.99': 119078, 'fp_0.99': 22844, 'fn_0.99': 1576, 'tp_0.99': 27858, 'mcc_0.99': 0.6490967340603657, 'AUC': 0.9468836665032172, 'logloss': 0.4015620967262793, 'average_precision': 0.9848476018810183, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315724, 'fp_0.5': 16736, 'fn_0.5': 15775, 'tp_0.5': 52883, 'mcc_0.5': 0.7159477036505506, 'tn_0.9': 301441, 'fp_0.9': 31019, 'fn_0.9': 7591, 'tp_0.9': 61067, 'mcc_0.9': 0.7130238135800924, 'tn_0.95': 294889, 'fp_0.95': 37571, 'fn_0.95': 5799, 'tp_0.95': 62859, 'mcc_0.95': 0.6977279513086468, 'tn_0.99': 278998, 'fp_0.99': 53462, 'fn_0.99': 3455, 'tp_0.99': 65203, 'mcc_0.99': 0.6510086175418484, 'AUC': 0.9494607067317912, 'logloss': 0.37792485757452987, 'average_precision': 0.9859093595236232, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134975, 'fp_0.5': 6947, 'fn_0.5': 7114, 'tp_0.5': 22320, 'mcc_0.5': 0.7109600736762907, 'tn_0.9': 119473, 'fp_0.9': 22449, 'fn_0.9': 1604, 'tp_0.9': 27830, 'mcc_0.9': 0.6521993721749831, 'tn_0.95': 114272, 'fp_0.95': 27650, 'fn_0.95': 1196, 'tp_0.95': 28238, 'mcc_0.95': 0.6151207837411873, 'tn_0.99': 107709, 'fp_0.99': 34213, 'fn_0.99': 910, 'tp_0.99': 28524, 'mcc_0.99': 0.5699997448131544, 'AUC': 0.94735305352597, 'logloss': 0.2012936658789981, 'average_precision': 0.9847290776847284, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316347, 'fp_0.5': 16113, 'fn_0.5': 16198, 'tp_0.5': 52460, 'mcc_0.5': 0.7159629015811126, 'tn_0.9': 279962, 'fp_0.9': 52498, 'fn_0.9': 3486, 'tp_0.9': 65172, 'mcc_0.9': 0.6546319966188541, 'tn_0.95': 267686, 'fp_0.95': 64774, 'fn_0.95': 2487, 'tp_0.95': 66171, 'mcc_0.95': 0.6176534169397593, 'tn_0.99': 252652, 'fp_0.99': 79808, 'fn_0.99': 1865, 'tp_0.99': 66793, 'mcc_0.99': 0.5731444031057936, 'AUC': 0.950247542579736, 'logloss': 0.19659703754113206, 'average_precision': 0.9858745994201579, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134604, 'fp_0.5': 7318, 'fn_0.5': 5701, 'tp_0.5': 23733, 'mcc_0.5': 0.739056462821212, 'tn_0.9': 121883, 'fp_0.9': 20039, 'fn_0.9': 975, 'tp_0.9': 28459, 'mcc_0.9': 0.691347598287492, 'tn_0.95': 116150, 'fp_0.95': 25772, 'fn_0.95': 532, 'tp_0.95': 28902, 'mcc_0.95': 0.6476313289965822, 'tn_0.99': 100584, 'fp_0.99': 41338, 'fn_0.99': 168, 'tp_0.99': 29266, 'mcc_0.99': 0.5387353500497457, 'AUC': 0.9681888173379696, 'logloss': 0.16871833395852878, 'average_precision': 0.9933828762637447, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315954, 'fp_0.5': 16506, 'fn_0.5': 12696, 'tp_0.5': 55962, 'mcc_0.5': 0.7493485135680906, 'tn_0.9': 286109, 'fp_0.9': 46351, 'fn_0.9': 1320, 'tp_0.9': 67338, 'mcc_0.9': 0.7031865473352251, 'tn_0.95': 272757, 'fp_0.95': 59703, 'fn_0.95': 469, 'tp_0.95': 68189, 'mcc_0.95': 0.6575638515276857, 'tn_0.99': 236611, 'fp_0.99': 95849, 'fn_0.99': 41, 'tp_0.99': 68617, 'mcc_0.99': 0.5445692251898934, 'AUC': 0.972907304737819, 'logloss': 0.15633382294829481, 'average_precision': 0.9945619355893209, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 26 out of 26
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 133591, 'fp_0.5': 8331, 'fn_0.5': 5937, 'tp_0.5': 23497, 'mcc_0.5': 0.7173103091682481, 'tn_0.9': 123385, 'fp_0.9': 18537, 'fn_0.9': 2141, 'tp_0.9': 27293, 'mcc_0.9': 0.6788497320809721, 'tn_0.95': 119799, 'fp_0.95': 22123, 'fn_0.95': 1632, 'tp_0.95': 27802, 'mcc_0.95': 0.6546699232601114, 'tn_0.99': 112008, 'fp_0.99': 29914, 'fn_0.99': 1065, 'tp_0.99': 28369, 'mcc_0.99': 0.5995382754365938, 'AUC': 0.9466305264696899, 'logloss': 0.33543675351780333, 'average_precision': 0.9842064009158841, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312941, 'fp_0.5': 19519, 'fn_0.5': 13608, 'tp_0.5': 55050, 'mcc_0.5': 0.7194539559226876, 'tn_0.9': 289100, 'fp_0.9': 43360, 'fn_0.9': 4662, 'tp_0.9': 63996, 'mcc_0.9': 0.6820299872122368, 'tn_0.95': 280673, 'fp_0.95': 51787, 'fn_0.95': 3555, 'tp_0.95': 65103, 'mcc_0.95': 0.6568503084783186, 'tn_0.99': 262317, 'fp_0.99': 70143, 'fn_0.99': 2211, 'tp_0.99': 66447, 'mcc_0.99': 0.6015334822975896, 'AUC': 0.948936982941273, 'logloss': 0.3166169252453231, 'average_precision': 0.9851595090273626, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135035, 'fp_0.5': 6887, 'fn_0.5': 7273, 'tp_0.5': 22161, 'mcc_0.5': 0.708080449206778, 'tn_0.9': 120016, 'fp_0.9': 21906, 'fn_0.9': 1664, 'tp_0.9': 27770, 'mcc_0.9': 0.6560040711258038, 'tn_0.95': 112768, 'fp_0.95': 29154, 'fn_0.95': 1104, 'tp_0.95': 28330, 'mcc_0.95': 0.6047882998557575, 'tn_0.99': 99246, 'fp_0.99': 42676, 'fn_0.99': 732, 'tp_0.99': 28702, 'mcc_0.99': 0.5160030192441475, 'AUC': 0.9465212145969868, 'logloss': 0.20273258734358163, 'average_precision': 0.9841398744968903, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316429, 'fp_0.5': 16031, 'fn_0.5': 16506, 'tp_0.5': 52152, 'mcc_0.5': 0.713335877745869, 'tn_0.9': 281259, 'fp_0.9': 51201, 'fn_0.9': 3591, 'tp_0.9': 65067, 'mcc_0.9': 0.6589134910541485, 'tn_0.95': 264115, 'fp_0.95': 68345, 'fn_0.95': 2275, 'tp_0.95': 66383, 'mcc_0.95': 0.6071250658354199, 'tn_0.99': 232636, 'fp_0.99': 99824, 'fn_0.99': 1511, 'tp_0.99': 67147, 'mcc_0.99': 0.5178566129182802, 'AUC': 0.9491109449263405, 'logloss': 0.1982456989151873, 'average_precision': 0.98515268854034, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134621, 'fp_0.5': 7301, 'fn_0.5': 5730, 'tp_0.5': 23704, 'mcc_0.5': 0.7386353249325739, 'tn_0.9': 121727, 'fp_0.9': 20195, 'fn_0.9': 968, 'tp_0.9': 28466, 'mcc_0.9': 0.689926520074663, 'tn_0.95': 116327, 'fp_0.95': 25595, 'fn_0.95': 549, 'tp_0.95': 28885, 'mcc_0.95': 0.6487870734117909, 'tn_0.99': 100761, 'fp_0.99': 41161, 'fn_0.99': 165, 'tp_0.99': 29269, 'mcc_0.99': 0.539969460092963, 'AUC': 0.9681432076059086, 'logloss': 0.16898948268305397, 'average_precision': 0.9933517292962463, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316016, 'fp_0.5': 16444, 'fn_0.5': 12780, 'tp_0.5': 55878, 'mcc_0.5': 0.7489219755844269, 'tn_0.9': 285899, 'fp_0.9': 46561, 'fn_0.9': 1261, 'tp_0.9': 67397, 'mcc_0.9': 0.7028751584876402, 'tn_0.95': 273374, 'fp_0.95': 59086, 'fn_0.95': 463, 'tp_0.95': 68195, 'mcc_0.95': 0.6599770758044046, 'tn_0.99': 236992, 'fp_0.99': 95468, 'fn_0.99': 52, 'tp_0.99': 68606, 'mcc_0.99': 0.5455235730076275, 'AUC': 0.9728924829588522, 'logloss': 0.1564313907014275, 'average_precision': 0.9945585411452564, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Program = raxml
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_all_ML_boot_raxml', 'feature_mean_all_ML_boot_raxml_binary', 'feature_mean_all_ML_boot_raxml_neighbors', 'feature_mean_all_ML_boot_raxml_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_min_ll_diff_norm', 'feature_max_ll_diff_norm', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty', 'feature_G', 'feature_I', 'feature_F', 'feature_free_parameters']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 29
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 29 out of 29
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134709, 'fp_0.5': 7294, 'fn_0.5': 5561, 'tp_0.5': 23792, 'mcc_0.5': 0.7422604092800047, 'tn_0.9': 122223, 'fp_0.9': 19780, 'fn_0.9': 901, 'tp_0.9': 28452, 'mcc_0.9': 0.6953769654993429, 'tn_0.95': 117011, 'fp_0.95': 24992, 'fn_0.95': 465, 'tp_0.95': 28888, 'mcc_0.95': 0.6558206691315138, 'tn_0.99': 103260, 'fp_0.99': 38743, 'fn_0.99': 118, 'tp_0.99': 29235, 'mcc_0.99': 0.5569340416705779, 'AUC': 0.9695873793414505, 'logloss': 0.1650846466921569, 'average_precision': 0.9937897482210926, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316233, 'fp_0.5': 16484, 'fn_0.5': 12514, 'tp_0.5': 55887, 'mcc_0.5': 0.7506495540336915, 'tn_0.9': 287210, 'fp_0.9': 45507, 'fn_0.9': 1291, 'tp_0.9': 67110, 'mcc_0.9': 0.706670035940004, 'tn_0.95': 275214, 'fp_0.95': 57503, 'fn_0.95': 495, 'tp_0.95': 67906, 'mcc_0.95': 0.665209075323472, 'tn_0.99': 243056, 'fp_0.99': 89661, 'fn_0.99': 44, 'tp_0.99': 68357, 'mcc_0.99': 0.5617870522715807, 'AUC': 0.973264573865093, 'logloss': 0.15464416254585228, 'average_precision': 0.9946690678985373, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 25
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 25 out of 25
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134950, 'fp_0.5': 7053, 'fn_0.5': 6153, 'tp_0.5': 23200, 'mcc_0.5': 0.7319334220593151, 'tn_0.9': 120516, 'fp_0.9': 21487, 'fn_0.9': 1073, 'tp_0.9': 28280, 'mcc_0.9': 0.6740364138542757, 'tn_0.95': 113905, 'fp_0.95': 28098, 'fn_0.95': 567, 'tp_0.95': 28786, 'mcc_0.95': 0.6263096223212031, 'tn_0.99': 95868, 'fp_0.99': 46135, 'fn_0.99': 136, 'tp_0.99': 29217, 'mcc_0.99': 0.5089419934965209, 'AUC': 0.9663425838946339, 'logloss': 0.1734863868773369, 'average_precision': 0.9929693921012327, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316949, 'fp_0.5': 15768, 'fn_0.5': 13905, 'tp_0.5': 54496, 'mcc_0.5': 0.7413998614833299, 'tn_0.9': 283263, 'fp_0.9': 49454, 'fn_0.9': 1616, 'tp_0.9': 66785, 'mcc_0.9': 0.6862073272776821, 'tn_0.95': 268309, 'fp_0.95': 64408, 'fn_0.95': 686, 'tp_0.95': 67715, 'mcc_0.95': 0.6372834539463403, 'tn_0.99': 226753, 'fp_0.99': 105964, 'fn_0.99': 87, 'tp_0.99': 68314, 'mcc_0.99': 0.5161244015941769, 'AUC': 0.9707886415146325, 'logloss': 0.16239032672442796, 'average_precision': 0.9940980484993411, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 30 out of 30
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 141994, 'fp_0.5': 9, 'fn_0.5': 27764, 'tp_0.5': 1589, 'mcc_0.5': 0.21195034998618878, 'tn_0.9': 141994, 'fp_0.9': 9, 'fn_0.9': 27764, 'tp_0.9': 1589, 'mcc_0.9': 0.21195034998618878, 'tn_0.95': 141994, 'fp_0.95': 9, 'fn_0.95': 27764, 'tp_0.95': 1589, 'mcc_0.95': 0.21195034998618878, 'tn_0.99': 141994, 'fp_0.99': 9, 'fn_0.99': 27764, 'tp_0.99': 1589, 'mcc_0.99': 0.21195034998618878, 'AUC': 0.9494182240845419, 'logloss': 5.598097742938132, 'average_precision': 0.9885591489157667, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 332703, 'fp_0.5': 14, 'fn_0.5': 64412, 'tp_0.5': 3989, 'mcc_0.5': 0.22049863136532158, 'tn_0.9': 332703, 'fp_0.9': 14, 'fn_0.9': 64412, 'tp_0.9': 3989, 'mcc_0.9': 0.22049863136532158, 'tn_0.95': 332703, 'fp_0.95': 14, 'fn_0.95': 64412, 'tp_0.95': 3989, 'mcc_0.95': 0.22049863136532158, 'tn_0.99': 332703, 'fp_0.99': 14, 'fn_0.99': 64412, 'tp_0.99': 3989, 'mcc_0.99': 0.22049863136532158, 'AUC': 0.9507938093647492, 'logloss': 5.547611205899984, 'average_precision': 0.988979408745456, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 136233, 'fp_0.5': 5770, 'fn_0.5': 10076, 'tp_0.5': 19277, 'mcc_0.5': 0.6570688289528165, 'tn_0.9': 113843, 'fp_0.9': 28160, 'fn_0.9': 1462, 'tp_0.9': 27891, 'mcc_0.9': 0.6038258807879427, 'tn_0.95': 102534, 'fp_0.95': 39469, 'fn_0.95': 638, 'tp_0.95': 28715, 'mcc_0.95': 0.53907502649989, 'tn_0.99': 81071, 'fp_0.99': 60932, 'fn_0.99': 126, 'tp_0.99': 29227, 'mcc_0.99': 0.42755378967921154, 'AUC': 0.9493700846422868, 'logloss': 0.2082439616708939, 'average_precision': 0.9884275387566983, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 318991, 'fp_0.5': 13726, 'fn_0.5': 23095, 'tp_0.5': 45306, 'mcc_0.5': 0.6593590459063141, 'tn_0.9': 267134, 'fp_0.9': 65583, 'fn_0.9': 3110, 'tp_0.9': 65291, 'mcc_0.9': 0.6075757166579265, 'tn_0.95': 240700, 'fp_0.95': 92017, 'fn_0.95': 1385, 'tp_0.95': 67016, 'mcc_0.95': 0.5406465886579682, 'tn_0.99': 190422, 'fp_0.99': 142295, 'fn_0.99': 277, 'tp_0.99': 68124, 'mcc_0.99': 0.4279669840621989, 'AUC': 0.9508239387571288, 'logloss': 0.20475075700211232, 'average_precision': 0.9888701410321303, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134707, 'fp_0.5': 7296, 'fn_0.5': 5423, 'tp_0.5': 23930, 'mcc_0.5': 0.7455392892673163, 'tn_0.9': 122551, 'fp_0.9': 19452, 'fn_0.9': 851, 'tp_0.9': 28502, 'mcc_0.9': 0.6999718658093415, 'tn_0.95': 117041, 'fp_0.95': 24962, 'fn_0.95': 416, 'tp_0.95': 28937, 'mcc_0.95': 0.6572840520329788, 'tn_0.99': 104569, 'fp_0.99': 37434, 'fn_0.99': 107, 'tp_0.99': 29246, 'mcc_0.99': 0.5662443594082138, 'AUC': 0.9703426121475015, 'logloss': 0.16312972243205112, 'average_precision': 0.9939676667021702, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316274, 'fp_0.5': 16443, 'fn_0.5': 12065, 'tp_0.5': 56336, 'mcc_0.5': 0.7555337317233319, 'tn_0.9': 288342, 'fp_0.9': 44375, 'fn_0.9': 1281, 'tp_0.9': 67120, 'mcc_0.9': 0.7118187831292633, 'tn_0.95': 275666, 'fp_0.95': 57051, 'fn_0.95': 455, 'tp_0.95': 67946, 'mcc_0.95': 0.6673851888664961, 'tn_0.99': 246977, 'fp_0.99': 85740, 'fn_0.99': 30, 'tp_0.99': 68371, 'mcc_0.99': 0.573617129986401, 'AUC': 0.9739605702769394, 'logloss': 0.15260513037399193, 'average_precision': 0.9948139375600398, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Program = fasttree
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_fasttree.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_min_ll_diff_norm', 'feature_max_ll_diff_norm', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty', 'feature_G', 'feature_I', 'feature_F', 'feature_free_parameters']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 25
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/fasttree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 25 out of 25
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Program = iqtree
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_iqtree.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_min_ll_diff_norm', 'feature_max_ll_diff_norm', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty', 'feature_G', 'feature_I', 'feature_F', 'feature_free_parameters']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 25
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 25 out of 25
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134595, 'fp_0.5': 7327, 'fn_0.5': 5712, 'tp_0.5': 23722, 'mcc_0.5': 0.73864694309446, 'tn_0.95': 116364, 'fp_0.95': 25558, 'fn_0.95': 561, 'tp_0.95': 28873, 'mcc_0.95': 0.6488239322808764, 'AUC': 0.9681150974399366, 'logloss': 0.16892635269762096, 'average_precision': 0.9933526365778704, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315960, 'fp_0.5': 16500, 'fn_0.5': 12713, 'tp_0.5': 55945, 'mcc_0.5': 0.7492164727512102, 'tn_0.95': 273147, 'fp_0.95': 59313, 'fn_0.95': 477, 'tp_0.95': 68181, 'mcc_0.95': 0.65896490868045, 'AUC': 0.9728656886250402, 'logloss': 0.15648194716411495, 'average_precision': 0.9945537413296814, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 25
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 25 out of 25
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134595, 'fp_0.5': 7327, 'fn_0.5': 5712, 'tp_0.5': 23722, 'mcc_0.5': 0.73864694309446, 'tn_0.95': 116364, 'fp_0.95': 25558, 'fn_0.95': 561, 'tp_0.95': 28873, 'mcc_0.95': 0.6488239322808764, 'AUC': 0.9681150974399366, 'logloss': 0.168926352697621, 'average_precision': 0.9933526365778704, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315960, 'fp_0.5': 16500, 'fn_0.5': 12713, 'tp_0.5': 55945, 'mcc_0.5': 0.7492164727512102, 'tn_0.95': 273147, 'fp_0.95': 59313, 'fn_0.95': 477, 'tp_0.95': 68181, 'mcc_0.95': 0.65896490868045, 'AUC': 0.9728656886250402, 'logloss': 0.15648194716411495, 'average_precision': 0.9945537413296814, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Comparing to bootstrap models
INFO:root:Bootstrap col bootstrap_support
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelbootstrap_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/bootstrap_support/model_inc_boot
INFO:root:Number of features after feature selection: 26 out of 26
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 141921, 'fp_0.5': 1, 'fn_0.5': 29216, 'tp_0.5': 218, 'mcc_0.5': 0.07811767916265619, 'tn_0.95': 141921, 'fp_0.95': 1, 'fn_0.95': 29216, 'tp_0.95': 218, 'mcc_0.95': 0.07811767916265619, 'AUC': 0.9330217849365996, 'logloss': 5.889159358111919, 'average_precision': 0.9802857495185502, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 332458, 'fp_0.5': 2, 'fn_0.5': 68127, 'tp_0.5': 531, 'mcc_0.5': 0.07990422810782345, 'tn_0.95': 332458, 'fp_0.95': 2, 'fn_0.95': 68127, 'tp_0.95': 531, 'mcc_0.95': 0.07990422810782345, 'AUC': 0.9337417602238112, 'logloss': 5.866470143905277, 'average_precision': 0.9804913008982211, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135675, 'fp_0.5': 6247, 'fn_0.5': 9443, 'tp_0.5': 19991, 'mcc_0.5': 0.6652868896228797, 'tn_0.95': 101191, 'fp_0.95': 40731, 'fn_0.95': 1562, 'tp_0.95': 27872, 'mcc_0.95': 0.5080223374290229, 'AUC': 0.9329541494242702, 'logloss': 0.22638812832531655, 'average_precision': 0.9802428621226617, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 318039, 'fp_0.5': 14421, 'fn_0.5': 21597, 'tp_0.5': 47061, 'mcc_0.5': 0.6712942091787137, 'tn_0.95': 237474, 'fp_0.95': 94986, 'fn_0.95': 3680, 'tp_0.95': 64978, 'mcc_0.95': 0.5082268097289823, 'AUC': 0.9337686153872756, 'logloss': 0.22399146328164196, 'average_precision': 0.980465293609326, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134498, 'fp_0.5': 7424, 'fn_0.5': 5432, 'tp_0.5': 24002, 'mcc_0.5': 0.7437969182310742, 'tn_0.95': 116546, 'fp_0.95': 25376, 'fn_0.95': 497, 'tp_0.95': 28937, 'mcc_0.95': 0.6520030227426281, 'AUC': 0.9691304537366656, 'logloss': 0.1661516198214501, 'average_precision': 0.9935923982895418, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315796, 'fp_0.5': 16664, 'fn_0.5': 12143, 'tp_0.5': 56515, 'mcc_0.5': 0.7538990097887883, 'tn_0.95': 273692, 'fp_0.95': 58768, 'fn_0.95': 451, 'tp_0.95': 68207, 'mcc_0.95': 0.6613190560701411, 'AUC': 0.9735668754461254, 'logloss': 0.15431504025047202, 'average_precision': 0.9946880793355648, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aLRT_iqtree_support
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aLRT_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aLRT_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 26 out of 26
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 134747, 'fp_0.5': 7175, 'fn_0.5': 6861, 'tp_0.5': 22573, 'mcc_0.5': 0.7133451860353393, 'tn_0.95': 125852, 'fp_0.95': 16070, 'fn_0.95': 2629, 'tp_0.95': 26805, 'mcc_0.95': 0.6944350240494798, 'AUC': 0.9468836665032172, 'logloss': 0.4015620967262793, 'average_precision': 0.9848476018810183, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315724, 'fp_0.5': 16736, 'fn_0.5': 15775, 'tp_0.5': 52883, 'mcc_0.5': 0.7159477036505506, 'tn_0.95': 294889, 'fp_0.95': 37571, 'fn_0.95': 5799, 'tp_0.95': 62859, 'mcc_0.95': 0.6977279513086468, 'AUC': 0.9494607067317912, 'logloss': 0.37792485757452987, 'average_precision': 0.9859093595236232, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134975, 'fp_0.5': 6947, 'fn_0.5': 7114, 'tp_0.5': 22320, 'mcc_0.5': 0.7109600736762907, 'tn_0.95': 114272, 'fp_0.95': 27650, 'fn_0.95': 1196, 'tp_0.95': 28238, 'mcc_0.95': 0.6151207837411873, 'AUC': 0.94735305352597, 'logloss': 0.2012936658789981, 'average_precision': 0.9847290776847284, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316347, 'fp_0.5': 16113, 'fn_0.5': 16198, 'tp_0.5': 52460, 'mcc_0.5': 0.7159629015811126, 'tn_0.95': 267686, 'fp_0.95': 64774, 'fn_0.95': 2487, 'tp_0.95': 66171, 'mcc_0.95': 0.6176534169397593, 'AUC': 0.950247542579736, 'logloss': 0.19659703754113206, 'average_precision': 0.9858745994201579, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134604, 'fp_0.5': 7318, 'fn_0.5': 5701, 'tp_0.5': 23733, 'mcc_0.5': 0.739056462821212, 'tn_0.95': 116150, 'fp_0.95': 25772, 'fn_0.95': 532, 'tp_0.95': 28902, 'mcc_0.95': 0.6476313289965822, 'AUC': 0.9681888173379696, 'logloss': 0.16871833395852878, 'average_precision': 0.9933828762637447, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 315954, 'fp_0.5': 16506, 'fn_0.5': 12696, 'tp_0.5': 55962, 'mcc_0.5': 0.7493485135680906, 'tn_0.95': 272757, 'fp_0.95': 59703, 'fn_0.95': 469, 'tp_0.95': 68189, 'mcc_0.95': 0.6575638515276857, 'AUC': 0.972907304737819, 'logloss': 0.15633382294829481, 'average_precision': 0.9945619355893209, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Bootstrap col feature_aBayes_iqtree_support
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_only_boot
INFO:root:Number of features after feature selection: 2 out of 2
INFO:root:Generating calibrated model for classification model
INFO:root:Building a final_modelfeature_aBayes_iqtree_support model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/iqtree/final_model/feature_aBayes_iqtree_support/model_inc_boot
INFO:root:Number of features after feature selection: 26 out of 26
INFO:root:Generating calibrated model for classification model
INFO:root:Model evaluation metrics {'tn_0.5': 133591, 'fp_0.5': 8331, 'fn_0.5': 5937, 'tp_0.5': 23497, 'mcc_0.5': 0.7173103091682481, 'tn_0.95': 119799, 'fp_0.95': 22123, 'fn_0.95': 1632, 'tp_0.95': 27802, 'mcc_0.95': 0.6546699232601114, 'AUC': 0.9466305264696899, 'logloss': 0.33543675351780333, 'average_precision': 0.9842064009158841, 'dataset': 'test', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 312941, 'fp_0.5': 19519, 'fn_0.5': 13608, 'tp_0.5': 55050, 'mcc_0.5': 0.7194539559226876, 'tn_0.95': 280673, 'fp_0.95': 51787, 'fn_0.95': 3555, 'tp_0.95': 65103, 'mcc_0.95': 0.6568503084783186, 'AUC': 0.948936982941273, 'logloss': 0.3166169252453231, 'average_precision': 0.9851595090273626, 'dataset': 'train', 'name': 'raw_only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 135035, 'fp_0.5': 6887, 'fn_0.5': 7273, 'tp_0.5': 22161, 'mcc_0.5': 0.708080449206778, 'tn_0.95': 112768, 'fp_0.95': 29154, 'fn_0.95': 1104, 'tp_0.95': 28330, 'mcc_0.95': 0.6047882998557575, 'AUC': 0.9465212145969868, 'logloss': 0.20273258734358163, 'average_precision': 0.9841398744968903, 'dataset': 'test', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316429, 'fp_0.5': 16031, 'fn_0.5': 16506, 'tp_0.5': 52152, 'mcc_0.5': 0.713335877745869, 'tn_0.95': 264115, 'fp_0.95': 68345, 'fn_0.95': 2275, 'tp_0.95': 66383, 'mcc_0.95': 0.6071250658354199, 'AUC': 0.9491109449263405, 'logloss': 0.1982456989151873, 'average_precision': 0.98515268854034, 'dataset': 'train', 'name': 'only_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 134621, 'fp_0.5': 7301, 'fn_0.5': 5730, 'tp_0.5': 23704, 'mcc_0.5': 0.7386353249325739, 'tn_0.95': 116327, 'fp_0.95': 25595, 'fn_0.95': 549, 'tp_0.95': 28885, 'mcc_0.95': 0.6487870734117909, 'AUC': 0.9681432076059086, 'logloss': 0.16898948268305397, 'average_precision': 0.9933517292962463, 'dataset': 'test', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316016, 'fp_0.5': 16444, 'fn_0.5': 12780, 'tp_0.5': 55878, 'mcc_0.5': 0.7489219755844269, 'tn_0.95': 273374, 'fp_0.95': 59086, 'fn_0.95': 463, 'tp_0.95': 68195, 'mcc_0.95': 0.6599770758044046, 'AUC': 0.9728924829588522, 'logloss': 0.15643139070142753, 'average_precision': 0.9945585411452564, 'dataset': 'train', 'name': 'inc_boot', 'metric_type': 'all_data'}
INFO:root:Program = raxml
INFO:root:Using existing training data in /Users/noa/Workspace/bootstrap_results/remote_results/full_data/simulations_df_raxml.tsv 
INFO:root:Generating optimized final model
INFO:root:Original number of trees in full data is 6094
INFO:root:Partitioning MSAs according to number of sequences
INFO:root:Number of MSAs in training data is 4683
INFO:root:Number of MSAs in test data is 2007
INFO:root:Number of different trees is 6094
INFO:root:Full features are: ['feature_mean_parsimony_trees', 'feature_mean_parsimony_trees_binary', 'feature_mean_parsimony_trees_neighbors', 'feature_mean_parsimony_trees_neighbors_binary', 'feature_mean_all_ML_boot_raxml', 'feature_mean_all_ML_boot_raxml_binary', 'feature_mean_all_ML_boot_raxml_neighbors', 'feature_mean_all_ML_boot_raxml_neighbors_binary', 'feature_mean_neighbor_brlen', 'feature_min_neighbor_brlen', 'feature_partition_branch', 'feature_partition_branch_vs_mean', 'feature_partition_size', 'feature_partition_size_ratio', 'feature_partition_divergence', 'feature_divergence_ratio', 'feature_min_ll_diff', 'feature_max_ll_diff', 'feature_min_ll_diff_norm', 'feature_max_ll_diff_norm', 'feature_msa_n_seq', 'feature_msa_n_loci', 'feature_msa_constant_sites_pct', 'feature_msa_n_unique_sites', 'feature_msa_pypythia_msa_difficulty', 'feature_G', 'feature_I', 'feature_F', 'feature_free_parameters']
INFO:root:Evaluating full standard model- including nni feautres, number of features is 29
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/full_model/model_stadard
INFO:root:Number of features after feature selection: 29 out of 29
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
INFO:root:Model evaluation metrics {'tn_0.5': 134709, 'fp_0.5': 7294, 'fn_0.5': 5561, 'tp_0.5': 23792, 'mcc_0.5': 0.7422604092800047, 'tn_0.95': 117011, 'fp_0.95': 24992, 'fn_0.95': 465, 'tp_0.95': 28888, 'mcc_0.95': 0.6558206691315138, 'AUC': 0.9695873793414505, 'logloss': 0.1650846466921569, 'average_precision': 0.9937897482210926, 'dataset': 'test', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Model evaluation metrics {'tn_0.5': 316233, 'fp_0.5': 16484, 'fn_0.5': 12514, 'tp_0.5': 55887, 'mcc_0.5': 0.7506495540336915, 'tn_0.95': 275214, 'fp_0.95': 57503, 'fn_0.95': 495, 'tp_0.95': 67906, 'mcc_0.95': 0.665209075323472, 'AUC': 0.973264573865093, 'logloss': 0.15464416254585228, 'average_precision': 0.9946690678985373, 'dataset': 'train', 'name': 'model_standard', 'metric_type': 'all_data'}
INFO:root:Evaluating fast standard model- no nni feautres, number of features is 29
INFO:root:Training ML model
INFO:root:Building a final_model model and saving to /Users/noa/Workspace/bootstrap_repo/ML_pipeline/raxml/final_model/fast_model/model_stadard
INFO:root:Number of features after feature selection: 29 out of 29
INFO:root:Generating calibrated model for classification model
INFO:root:Evaluating model performance
