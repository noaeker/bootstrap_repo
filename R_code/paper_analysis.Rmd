---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
library(scales)
library(tidyverse)
library(caret)
library(ggpubr)
library(pROC)
```

```{r}
prefix = "/Users/noa/Workspace/bootstrap_repo/ML_pipeline"


fasttree_all_models_performance = read_tsv(paste(prefix,"/fasttree/all_models_performance.tsv", sep = ""))
fasttree_final_models_performance = read_tsv(paste(prefix,"/fasttree/final_model_performance.tsv", sep = ""))
fasttree_group_performance = read_tsv(paste(prefix,"/fasttree/groups_performance.tsv", sep = ""))
fasttree_vi =  read_tsv(paste(prefix,"/fasttree/model_standard_vi.tsv", sep = ""))
fasttree_enriched_test = read_tsv(paste(prefix,"/fasttree/test_model_standard_enriched.tsv", sep = ""))
#####
iqtree_all_models_performance = read_tsv(paste(prefix,"/iqtree/all_models_performance.tsv", sep = ""))
iqtree_final_models_performance = read_tsv(paste(prefix,"/iqtree/final_model_performance.tsv", sep = ""))
iqtree_group_performance = read_tsv(paste(prefix,"/iqtree/groups_performance.tsv", sep = ""))
iqtree_vi =  read_tsv(paste(prefix,"/iqtree/model_standard_vi.tsv", sep = ""))
iqtree_enriched_test = read_tsv(paste(prefix,"/iqtree/test_model_standard_enriched.tsv", sep = ""))
#####
raxml_all_models_performance = read_tsv(paste(prefix,"/raxml/all_models_performance.tsv", sep = ""))
raxml_final_models_performance = read_tsv(paste(prefix,"/raxml/final_model_performance.tsv", sep = ""))
raxml_group_performance = read_tsv(paste(prefix,"/raxml/groups_performance.tsv", sep = ""))
raxml_vi =  read_tsv(paste(prefix,"/raxml/model_standard_vi.tsv", sep = ""))
raxml_enriched_test = read_tsv(paste(prefix,"/raxml/test_model_standard_enriched.tsv", sep = ""))


```

Choose specific program
```{r}
program = 'raxml'
if (program=='fasttree') {
    all_models_performance = fasttree_all_models_performance
    final_models_performance = fasttree_final_models_performance
    group_performance = fasttree_group_performance
    vi = fasttree_vi
    enriched_test = fasttree_enriched_test
    
} else if (program=='iqtree') {
    all_models_performance = iqtree_all_models_performance
    final_models_performance = iqtree_final_models_performance
    group_performance = iqtree_group_performance
    vi = fasttree_vi
    enriched_test = iqtree_enriched_test
} else if (program=='raxml') {
    all_models_performance = raxml_all_models_performance
    final_models_performance = raxml_final_models_performance
    group_performance = raxml_group_performance
    vi = fasttree_vi
    enriched_test = raxml_enriched_test
}
```


General performance
```{r}
final_models_performance  %>% filter (dataset=='test', metric_type=='all_data') %>% dplyr::select (analysis_type,name,balanced_accuracy_score, mcc)
```


```{r}

```




Variable importance 
```{r}
vi %>% arrange (-`Gini-importance`)
```



Confusion matrix

```{r}
ggplotConfusionMatrix <- function(m){
  mytitle <- ""#paste("Accuracy", percent_format()(m$overall[1]))
                  # "Kappa", percent_format()(m$overall[2]))
  p <-
    ggplot(data = as.data.frame(m$table) ,
           aes(x = Reference, y = Prediction)) +
    geom_tile(aes(fill = log(Freq)), colour = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    geom_text(aes(x = Reference, y = Prediction, label = scales::comma(Freq))) +
    theme(legend.position = "none") +
    ggtitle(mytitle)+theme(text = element_text(size = 13))
  return(p)
}
conf_data<-enriched_test %>% dplyr::select (prob_predictions, true_label) %>% mutate (pred_status = prob_predictions>0.5) 

obs<- factor(conf_data %>% pull (true_label))
pred<- factor(conf_data %>% pull (pred_status))


confusion_plot<-ggplotConfusionMatrix(confusionMatrix(data = pred, reference= obs))+theme(legend.position = "none")

```
Prediction metrics


```{r}
library(predtools)
library(MASS)
library(caret)

error_vs_size<- all_models_performance %>% filter (metric_type=='all_data', dataset =='test')
error_vs_size_plt = error_vs_size %>% mutate(n_MSAs = sample_frac) %>% ggplot(aes(x=n_MSAs, y = AUC))+geom_line()+ expand_limits(y = 0.5)+xlab("Number of MSAs")+ theme(text = element_text(size = 13))+ylab("AUC")+geom_point()

rocobj <- roc(enriched_test$true_label, enriched_test$prob_predictions)
auc <- round(auc(enriched_test$true_label, enriched_test$prob_predictions),3)

global_max_auc_plt<-ggroc(rocobj,colour = 'steelblue', size = 2)+
  ggtitle(paste0('AUC = ', auc))+theme(text = element_text(size = 13))+xlab("Specificity")




ggarrange(global_max_auc_plt,confusion_plot,error_vs_size_plt, labels = c("A","B","C"),align = "h", nrow = 2, ncol = 2 )

```
Group performance

```{r}
test_group_performance<- group_performance %>% filter (dataset=='test')

Pypythia_error<-test_group_performance %>% filter (grouping_col_name =='msa_difficulty_group') %>% ggplot(aes(y=grouping_col, x=Balanced_Accuracy))+geom_col()+ expand_limits(y = c(0.5,1))+ylab('MSA\ndifficulty')+ xlab('Balanced\naccuracy')+theme(text = element_text(size = 11))

n_seq_error<-test_group_performance %>% filter (grouping_col_name =='n_seq_group')  %>% ggplot(aes(y=grouping_col, x=Balanced_Accuracy))+geom_col()+ expand_limits(y = c(0.5,1))+ylab('Number\nof sequences')+xlab('Balanced\naccuracy')+theme(text = element_text(size = 11))

#>%  mutate(grouping_col = factor(grouping_col, levels = c('(99.999, 219.0]','(219.0, 546.0]','(546.0, 1519.0]','(1519.0, 16115.0]')))

n_loci_error<-test_group_performance %>% filter (grouping_col_name =='feature_msa_n_loci') %>% ggplot(aes(y=grouping_col, x=Balanced_Accuracy))+geom_col()+ expand_limits(y = c(0.5,1))+ylab('Number\nof positions')+xlab('Balanced\naccuracy')+theme(text = element_text(size = 11))

Pypythia_scatter<-enriched_test %>% dplyr::select (msa_path,prob_predictions,  feature_msa_pypythia_msa_difficulty) %>% group_by(msa_path,feature_msa_pypythia_msa_difficulty) %>% summarise(mean_prob = mean(prob_predictions)) %>% ggplot(aes(x=feature_msa_pypythia_msa_difficulty, y = mean_prob))+geom_point(size = 0.7)+xlab("MSA\ndifficulty")+ylab("Predicted\nprobability")+theme(text = element_text(size = 11))

seq_scatter<-enriched_test %>% dplyr::select (msa_path,prob_predictions, feature_msa_n_seq, feature_msa_pypythia_msa_difficulty) %>% group_by(msa_path,feature_msa_n_seq) %>% summarise(mean_prob = mean(prob_predictions)) %>% ggplot(aes(x=feature_msa_n_seq, y = mean_prob))+geom_point(size = 0.7)+xlab("Number of\nsequences")+ylab("Predicted\nprobability")+theme(text = element_text(size = 11))

n_loci_scatter<-enriched_test %>% dplyr::select (msa_path,prob_predictions, feature_msa_n_loci) %>% group_by(msa_path,feature_msa_n_loci) %>% summarise(mean_prob = mean(prob_predictions)) %>% ggplot(aes(x=feature_msa_n_loci, y = mean_prob))+geom_point(size = 0.7)+xlab("Number of\n positions")+ylab("Predicted\nprobability")+theme(text = element_text(size = 11))

ggarrange(seq_scatter,Pypythia_scatter,n_loci_scatter, n_seq_error,Pypythia_error, n_loci_error,labels = c("A","C","E","B","D","F"),align = "h", nrow = 3, ncol = 3, legend = "bottom",vjust= 1)
#error_vs_group_5_5_including_plt


```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

